{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a857df8-e46a-4ff0-aa98-356e9dbe93f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.563625  [    0/16250]\n",
      "loss: 0.561814  [   40/16250]\n",
      "loss: 0.584692  [   80/16250]\n",
      "loss: 0.566754  [  120/16250]\n",
      "loss: 0.579445  [  160/16250]\n",
      "loss: 0.566357  [  200/16250]\n",
      "loss: 0.552660  [  240/16250]\n",
      "loss: 0.571658  [  280/16250]\n",
      "loss: 0.565441  [  320/16250]\n",
      "loss: 0.561094  [  360/16250]\n",
      "loss: 0.574575  [  400/16250]\n",
      "loss: 0.574128  [  440/16250]\n",
      "loss: 0.559630  [  480/16250]\n",
      "loss: 0.567170  [  520/16250]\n",
      "loss: 0.573294  [  560/16250]\n",
      "loss: 0.585766  [  600/16250]\n",
      "loss: 0.586522  [  640/16250]\n",
      "loss: 0.557342  [  680/16250]\n",
      "loss: 0.572571  [  720/16250]\n",
      "loss: 0.589443  [  760/16250]\n",
      "loss: 0.577012  [  800/16250]\n",
      "loss: 0.578849  [  840/16250]\n",
      "loss: 0.576713  [  880/16250]\n",
      "loss: 0.558169  [  920/16250]\n",
      "loss: 0.573429  [  960/16250]\n",
      "loss: 0.569093  [ 1000/16250]\n",
      "loss: 0.560899  [ 1040/16250]\n",
      "loss: 0.567157  [ 1080/16250]\n",
      "loss: 0.555025  [ 1120/16250]\n",
      "loss: 0.564104  [ 1160/16250]\n",
      "loss: 0.572829  [ 1200/16250]\n",
      "loss: 0.567605  [ 1240/16250]\n",
      "loss: 0.566699  [ 1280/16250]\n",
      "loss: 0.553002  [ 1320/16250]\n",
      "loss: 0.570530  [ 1360/16250]\n",
      "loss: 0.592770  [ 1400/16250]\n",
      "loss: 0.565330  [ 1440/16250]\n",
      "loss: 0.574673  [ 1480/16250]\n",
      "loss: 0.584576  [ 1520/16250]\n",
      "loss: 0.570642  [ 1560/16250]\n",
      "loss: 0.582731  [ 1600/16250]\n",
      "loss: 0.582057  [ 1640/16250]\n",
      "loss: 0.567722  [ 1680/16250]\n",
      "loss: 0.577045  [ 1720/16250]\n",
      "loss: 0.544645  [ 1760/16250]\n",
      "loss: 0.564958  [ 1800/16250]\n",
      "loss: 0.550136  [ 1840/16250]\n",
      "loss: 0.565455  [ 1880/16250]\n",
      "loss: 0.576011  [ 1920/16250]\n",
      "loss: 0.562480  [ 1960/16250]\n",
      "loss: 0.558157  [ 2000/16250]\n",
      "loss: 0.558107  [ 2040/16250]\n",
      "loss: 0.582741  [ 2080/16250]\n",
      "loss: 0.581316  [ 2120/16250]\n",
      "loss: 0.561246  [ 2160/16250]\n",
      "loss: 0.564808  [ 2200/16250]\n",
      "loss: 0.570821  [ 2240/16250]\n",
      "loss: 0.543569  [ 2280/16250]\n",
      "loss: 0.565280  [ 2320/16250]\n",
      "loss: 0.579874  [ 2360/16250]\n",
      "loss: 0.572843  [ 2400/16250]\n",
      "loss: 0.572227  [ 2440/16250]\n",
      "loss: 0.573693  [ 2480/16250]\n",
      "loss: 0.569775  [ 2520/16250]\n",
      "loss: 0.564092  [ 2560/16250]\n",
      "loss: 0.567082  [ 2600/16250]\n",
      "loss: 0.561921  [ 2640/16250]\n",
      "loss: 0.562259  [ 2680/16250]\n",
      "loss: 0.566612  [ 2720/16250]\n",
      "loss: 0.602672  [ 2760/16250]\n",
      "loss: 0.562537  [ 2800/16250]\n",
      "loss: 0.574677  [ 2840/16250]\n",
      "loss: 0.564638  [ 2880/16250]\n",
      "loss: 0.560056  [ 2920/16250]\n",
      "loss: 0.559633  [ 2960/16250]\n",
      "loss: 0.577298  [ 3000/16250]\n",
      "loss: 0.572192  [ 3040/16250]\n",
      "loss: 0.590511  [ 3080/16250]\n",
      "loss: 0.579839  [ 3120/16250]\n",
      "loss: 0.580622  [ 3160/16250]\n",
      "loss: 0.585549  [ 3200/16250]\n",
      "loss: 0.579820  [ 3240/16250]\n",
      "loss: 0.559228  [ 3280/16250]\n",
      "loss: 0.575733  [ 3320/16250]\n",
      "loss: 0.583901  [ 3360/16250]\n",
      "loss: 0.556058  [ 3400/16250]\n",
      "loss: 0.569268  [ 3440/16250]\n",
      "loss: 0.580223  [ 3480/16250]\n",
      "loss: 0.579837  [ 3520/16250]\n",
      "loss: 0.565092  [ 3560/16250]\n",
      "loss: 0.562039  [ 3600/16250]\n",
      "loss: 0.568707  [ 3640/16250]\n",
      "loss: 0.552951  [ 3680/16250]\n",
      "loss: 0.573464  [ 3720/16250]\n",
      "loss: 0.553212  [ 3760/16250]\n",
      "loss: 0.580082  [ 3800/16250]\n",
      "loss: 0.591514  [ 3840/16250]\n",
      "loss: 0.565382  [ 3880/16250]\n",
      "loss: 0.569657  [ 3920/16250]\n",
      "loss: 0.559648  [ 3960/16250]\n",
      "loss: 0.567994  [ 4000/16250]\n",
      "loss: 0.580312  [ 4040/16250]\n",
      "loss: 0.568176  [ 4080/16250]\n",
      "loss: 0.562150  [ 4120/16250]\n",
      "loss: 0.568351  [ 4160/16250]\n",
      "loss: 0.566003  [ 4200/16250]\n",
      "loss: 0.562704  [ 4240/16250]\n",
      "loss: 0.552659  [ 4280/16250]\n",
      "loss: 0.570702  [ 4320/16250]\n",
      "loss: 0.556527  [ 4360/16250]\n",
      "loss: 0.580059  [ 4400/16250]\n",
      "loss: 0.573223  [ 4440/16250]\n",
      "loss: 0.575542  [ 4480/16250]\n",
      "loss: 0.583007  [ 4520/16250]\n",
      "loss: 0.542915  [ 4560/16250]\n",
      "loss: 0.580945  [ 4600/16250]\n",
      "loss: 0.570495  [ 4640/16250]\n",
      "loss: 0.573649  [ 4680/16250]\n",
      "loss: 0.546021  [ 4720/16250]\n",
      "loss: 0.562526  [ 4760/16250]\n",
      "loss: 0.592481  [ 4800/16250]\n",
      "loss: 0.577401  [ 4840/16250]\n",
      "loss: 0.558694  [ 4880/16250]\n",
      "loss: 0.563498  [ 4920/16250]\n",
      "loss: 0.556291  [ 4960/16250]\n",
      "loss: 0.567048  [ 5000/16250]\n",
      "loss: 0.566137  [ 5040/16250]\n",
      "loss: 0.597452  [ 5080/16250]\n",
      "loss: 0.588355  [ 5120/16250]\n",
      "loss: 0.572643  [ 5160/16250]\n",
      "loss: 0.571361  [ 5200/16250]\n",
      "loss: 0.567856  [ 5240/16250]\n",
      "loss: 0.561351  [ 5280/16250]\n",
      "loss: 0.552565  [ 5320/16250]\n",
      "loss: 0.558984  [ 5360/16250]\n",
      "loss: 0.589087  [ 5400/16250]\n",
      "loss: 0.589918  [ 5440/16250]\n",
      "loss: 0.551829  [ 5480/16250]\n",
      "loss: 0.568040  [ 5520/16250]\n",
      "loss: 0.585192  [ 5560/16250]\n",
      "loss: 0.570969  [ 5600/16250]\n",
      "loss: 0.588083  [ 5640/16250]\n",
      "loss: 0.574060  [ 5680/16250]\n",
      "loss: 0.545520  [ 5720/16250]\n",
      "loss: 0.589187  [ 5760/16250]\n",
      "loss: 0.574342  [ 5800/16250]\n",
      "loss: 0.563571  [ 5840/16250]\n",
      "loss: 0.570254  [ 5880/16250]\n",
      "loss: 0.558049  [ 5920/16250]\n",
      "loss: 0.567010  [ 5960/16250]\n",
      "loss: 0.591119  [ 6000/16250]\n",
      "loss: 0.574619  [ 6040/16250]\n",
      "loss: 0.556912  [ 6080/16250]\n",
      "loss: 0.563903  [ 6120/16250]\n",
      "loss: 0.570394  [ 6160/16250]\n",
      "loss: 0.592234  [ 6200/16250]\n",
      "loss: 0.568236  [ 6240/16250]\n",
      "loss: 0.572719  [ 6280/16250]\n",
      "loss: 0.564912  [ 6320/16250]\n",
      "loss: 0.599073  [ 6360/16250]\n",
      "loss: 0.564378  [ 6400/16250]\n",
      "loss: 0.581639  [ 6440/16250]\n",
      "loss: 0.599003  [ 6480/16250]\n",
      "loss: 0.569546  [ 6520/16250]\n",
      "loss: 0.556696  [ 6560/16250]\n",
      "loss: 0.567370  [ 6600/16250]\n",
      "loss: 0.574492  [ 6640/16250]\n",
      "loss: 0.544780  [ 6680/16250]\n",
      "loss: 0.560247  [ 6720/16250]\n",
      "loss: 0.578370  [ 6760/16250]\n",
      "loss: 0.586613  [ 6800/16250]\n",
      "loss: 0.575678  [ 6840/16250]\n",
      "loss: 0.554628  [ 6880/16250]\n",
      "loss: 0.595480  [ 6920/16250]\n",
      "loss: 0.566234  [ 6960/16250]\n",
      "loss: 0.573401  [ 7000/16250]\n",
      "loss: 0.585018  [ 7040/16250]\n",
      "loss: 0.569866  [ 7080/16250]\n",
      "loss: 0.562041  [ 7120/16250]\n",
      "loss: 0.559779  [ 7160/16250]\n",
      "loss: 0.555725  [ 7200/16250]\n",
      "loss: 0.544673  [ 7240/16250]\n",
      "loss: 0.561864  [ 7280/16250]\n",
      "loss: 0.580310  [ 7320/16250]\n",
      "loss: 0.577824  [ 7360/16250]\n",
      "loss: 0.580843  [ 7400/16250]\n",
      "loss: 0.591362  [ 7440/16250]\n",
      "loss: 0.559830  [ 7480/16250]\n",
      "loss: 0.590181  [ 7520/16250]\n",
      "loss: 0.565032  [ 7560/16250]\n",
      "loss: 0.558875  [ 7600/16250]\n",
      "loss: 0.567883  [ 7640/16250]\n",
      "loss: 0.566379  [ 7680/16250]\n",
      "loss: 0.560533  [ 7720/16250]\n",
      "loss: 0.550492  [ 7760/16250]\n",
      "loss: 0.561394  [ 7800/16250]\n",
      "loss: 0.566666  [ 7840/16250]\n",
      "loss: 0.569765  [ 7880/16250]\n",
      "loss: 0.570433  [ 7920/16250]\n",
      "loss: 0.559496  [ 7960/16250]\n",
      "loss: 0.560186  [ 8000/16250]\n",
      "loss: 0.570267  [ 8040/16250]\n",
      "loss: 0.575056  [ 8080/16250]\n",
      "loss: 0.585374  [ 8120/16250]\n",
      "loss: 0.555921  [ 8160/16250]\n",
      "loss: 0.550325  [ 8200/16250]\n",
      "loss: 0.572098  [ 8240/16250]\n",
      "loss: 0.557184  [ 8280/16250]\n",
      "loss: 0.570930  [ 8320/16250]\n",
      "loss: 0.563228  [ 8360/16250]\n",
      "loss: 0.581373  [ 8400/16250]\n",
      "loss: 0.559166  [ 8440/16250]\n",
      "loss: 0.582731  [ 8480/16250]\n",
      "loss: 0.565046  [ 8520/16250]\n",
      "loss: 0.575792  [ 8560/16250]\n",
      "loss: 0.566318  [ 8600/16250]\n",
      "loss: 0.553703  [ 8640/16250]\n",
      "loss: 0.562441  [ 8680/16250]\n",
      "loss: 0.543418  [ 8720/16250]\n",
      "loss: 0.574517  [ 8760/16250]\n",
      "loss: 0.578391  [ 8800/16250]\n",
      "loss: 0.585513  [ 8840/16250]\n",
      "loss: 0.582142  [ 8880/16250]\n",
      "loss: 0.556832  [ 8920/16250]\n",
      "loss: 0.563711  [ 8960/16250]\n",
      "loss: 0.563412  [ 9000/16250]\n",
      "loss: 0.566489  [ 9040/16250]\n",
      "loss: 0.579600  [ 9080/16250]\n",
      "loss: 0.567880  [ 9120/16250]\n",
      "loss: 0.559074  [ 9160/16250]\n",
      "loss: 0.577711  [ 9200/16250]\n",
      "loss: 0.572348  [ 9240/16250]\n",
      "loss: 0.571875  [ 9280/16250]\n",
      "loss: 0.565138  [ 9320/16250]\n",
      "loss: 0.577774  [ 9360/16250]\n",
      "loss: 0.571520  [ 9400/16250]\n",
      "loss: 0.568372  [ 9440/16250]\n",
      "loss: 0.567548  [ 9480/16250]\n",
      "loss: 0.579602  [ 9520/16250]\n",
      "loss: 0.559308  [ 9560/16250]\n",
      "loss: 0.572865  [ 9600/16250]\n",
      "loss: 0.580781  [ 9640/16250]\n",
      "loss: 0.577935  [ 9680/16250]\n",
      "loss: 0.567584  [ 9720/16250]\n",
      "loss: 0.568409  [ 9760/16250]\n",
      "loss: 0.562558  [ 9800/16250]\n",
      "loss: 0.557682  [ 9840/16250]\n",
      "loss: 0.556049  [ 9880/16250]\n",
      "loss: 0.570299  [ 9920/16250]\n",
      "loss: 0.568378  [ 9960/16250]\n",
      "loss: 0.583670  [10000/16250]\n",
      "loss: 0.562868  [10040/16250]\n",
      "loss: 0.566119  [10080/16250]\n",
      "loss: 0.585605  [10120/16250]\n",
      "loss: 0.568470  [10160/16250]\n",
      "loss: 0.575897  [10200/16250]\n",
      "loss: 0.587649  [10240/16250]\n",
      "loss: 0.564262  [10280/16250]\n",
      "loss: 0.551668  [10320/16250]\n",
      "loss: 0.571534  [10360/16250]\n",
      "loss: 0.590380  [10400/16250]\n",
      "loss: 0.565654  [10440/16250]\n",
      "loss: 0.561112  [10480/16250]\n",
      "loss: 0.567265  [10520/16250]\n",
      "loss: 0.583423  [10560/16250]\n",
      "loss: 0.556898  [10600/16250]\n",
      "loss: 0.538653  [10640/16250]\n",
      "loss: 0.575673  [10680/16250]\n",
      "loss: 0.553321  [10720/16250]\n",
      "loss: 0.557811  [10760/16250]\n",
      "loss: 0.577826  [10800/16250]\n",
      "loss: 0.557515  [10840/16250]\n",
      "loss: 0.551609  [10880/16250]\n",
      "loss: 0.558484  [10920/16250]\n",
      "loss: 0.560977  [10960/16250]\n",
      "loss: 0.589246  [11000/16250]\n",
      "loss: 0.559669  [11040/16250]\n",
      "loss: 0.545895  [11080/16250]\n",
      "loss: 0.558987  [11120/16250]\n",
      "loss: 0.589440  [11160/16250]\n",
      "loss: 0.561355  [11200/16250]\n",
      "loss: 0.577631  [11240/16250]\n",
      "loss: 0.576845  [11280/16250]\n",
      "loss: 0.564202  [11320/16250]\n",
      "loss: 0.544319  [11360/16250]\n",
      "loss: 0.552612  [11400/16250]\n",
      "loss: 0.598724  [11440/16250]\n",
      "loss: 0.569932  [11480/16250]\n",
      "loss: 0.556496  [11520/16250]\n",
      "loss: 0.582356  [11560/16250]\n",
      "loss: 0.553545  [11600/16250]\n",
      "loss: 0.569598  [11640/16250]\n",
      "loss: 0.585227  [11680/16250]\n",
      "loss: 0.567383  [11720/16250]\n",
      "loss: 0.532287  [11760/16250]\n",
      "loss: 0.559784  [11800/16250]\n",
      "loss: 0.582016  [11840/16250]\n",
      "loss: 0.572770  [11880/16250]\n",
      "loss: 0.553950  [11920/16250]\n",
      "loss: 0.540824  [11960/16250]\n",
      "loss: 0.567105  [12000/16250]\n",
      "loss: 0.565394  [12040/16250]\n",
      "loss: 0.564992  [12080/16250]\n",
      "loss: 0.566390  [12120/16250]\n",
      "loss: 0.541190  [12160/16250]\n",
      "loss: 0.565291  [12200/16250]\n",
      "loss: 0.568089  [12240/16250]\n",
      "loss: 0.554516  [12280/16250]\n",
      "loss: 0.549295  [12320/16250]\n",
      "loss: 0.555257  [12360/16250]\n",
      "loss: 0.570652  [12400/16250]\n",
      "loss: 0.576249  [12440/16250]\n",
      "loss: 0.569557  [12480/16250]\n",
      "loss: 0.585086  [12520/16250]\n",
      "loss: 0.544196  [12560/16250]\n",
      "loss: 0.567640  [12600/16250]\n",
      "loss: 0.576836  [12640/16250]\n",
      "loss: 0.566762  [12680/16250]\n",
      "loss: 0.567456  [12720/16250]\n",
      "loss: 0.549192  [12760/16250]\n",
      "loss: 0.584803  [12800/16250]\n",
      "loss: 0.571915  [12840/16250]\n",
      "loss: 0.580716  [12880/16250]\n",
      "loss: 0.560976  [12920/16250]\n",
      "loss: 0.564723  [12960/16250]\n",
      "loss: 0.556755  [13000/16250]\n",
      "loss: 0.569446  [13040/16250]\n",
      "loss: 0.552705  [13080/16250]\n",
      "loss: 0.542123  [13120/16250]\n",
      "loss: 0.555598  [13160/16250]\n",
      "loss: 0.555707  [13200/16250]\n",
      "loss: 0.577989  [13240/16250]\n",
      "loss: 0.578329  [13280/16250]\n",
      "loss: 0.565222  [13320/16250]\n",
      "loss: 0.569372  [13360/16250]\n",
      "loss: 0.578706  [13400/16250]\n",
      "loss: 0.573121  [13440/16250]\n",
      "loss: 0.564609  [13480/16250]\n",
      "loss: 0.559968  [13520/16250]\n",
      "loss: 0.564807  [13560/16250]\n",
      "loss: 0.572035  [13600/16250]\n",
      "loss: 0.572858  [13640/16250]\n",
      "loss: 0.549653  [13680/16250]\n",
      "loss: 0.528642  [13720/16250]\n",
      "loss: 0.578258  [13760/16250]\n",
      "loss: 0.554970  [13800/16250]\n",
      "loss: 0.579515  [13840/16250]\n",
      "loss: 0.576593  [13880/16250]\n",
      "loss: 0.552911  [13920/16250]\n",
      "loss: 0.537350  [13960/16250]\n",
      "loss: 0.572664  [14000/16250]\n",
      "loss: 0.597788  [14040/16250]\n",
      "loss: 0.564943  [14080/16250]\n",
      "loss: 0.596027  [14120/16250]\n",
      "loss: 0.564418  [14160/16250]\n",
      "loss: 0.565910  [14200/16250]\n",
      "loss: 0.573191  [14240/16250]\n",
      "loss: 0.568392  [14280/16250]\n",
      "loss: 0.574244  [14320/16250]\n",
      "loss: 0.560014  [14360/16250]\n",
      "loss: 0.576760  [14400/16250]\n",
      "loss: 0.574823  [14440/16250]\n",
      "loss: 0.565278  [14480/16250]\n",
      "loss: 0.543167  [14520/16250]\n",
      "loss: 0.562030  [14560/16250]\n",
      "loss: 0.565357  [14600/16250]\n",
      "loss: 0.545593  [14640/16250]\n",
      "loss: 0.583750  [14680/16250]\n",
      "loss: 0.573753  [14720/16250]\n",
      "loss: 0.549538  [14760/16250]\n",
      "loss: 0.548640  [14800/16250]\n",
      "loss: 0.565455  [14840/16250]\n",
      "loss: 0.557967  [14880/16250]\n",
      "loss: 0.575540  [14920/16250]\n",
      "loss: 0.587359  [14960/16250]\n",
      "loss: 0.580682  [15000/16250]\n",
      "loss: 0.565096  [15040/16250]\n",
      "loss: 0.566604  [15080/16250]\n",
      "loss: 0.541572  [15120/16250]\n",
      "loss: 0.589090  [15160/16250]\n",
      "loss: 0.552487  [15200/16250]\n",
      "loss: 0.586693  [15240/16250]\n",
      "loss: 0.585009  [15280/16250]\n",
      "loss: 0.557252  [15320/16250]\n",
      "loss: 0.569232  [15360/16250]\n",
      "loss: 0.551217  [15400/16250]\n",
      "loss: 0.572044  [15440/16250]\n",
      "loss: 0.573352  [15480/16250]\n",
      "loss: 0.571540  [15520/16250]\n",
      "loss: 0.561960  [15560/16250]\n",
      "loss: 0.593386  [15600/16250]\n",
      "loss: 0.583162  [15640/16250]\n",
      "loss: 0.569895  [15680/16250]\n",
      "loss: 0.570471  [15720/16250]\n",
      "loss: 0.565628  [15760/16250]\n",
      "loss: 0.540113  [15800/16250]\n",
      "loss: 0.551561  [15840/16250]\n",
      "loss: 0.559838  [15880/16250]\n",
      "loss: 0.562303  [15920/16250]\n",
      "loss: 0.568172  [15960/16250]\n",
      "loss: 0.563739  [16000/16250]\n",
      "loss: 0.552015  [16040/16250]\n",
      "loss: 0.562973  [16080/16250]\n",
      "loss: 0.559918  [16120/16250]\n",
      "loss: 0.551549  [16160/16250]\n",
      "loss: 0.567882  [16200/16250]\n",
      "loss: 0.555311  [ 8120/16250]\n",
      "Avg loss: 0.769686 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.555677  [    0/16250]\n",
      "loss: 0.561884  [   40/16250]\n",
      "loss: 0.548768  [   80/16250]\n",
      "loss: 0.595440  [  120/16250]\n",
      "loss: 0.537216  [  160/16250]\n",
      "loss: 0.557343  [  200/16250]\n",
      "loss: 0.557100  [  240/16250]\n",
      "loss: 0.580109  [  280/16250]\n",
      "loss: 0.552081  [  320/16250]\n",
      "loss: 0.584301  [  360/16250]\n",
      "loss: 0.553321  [  400/16250]\n",
      "loss: 0.531647  [  440/16250]\n",
      "loss: 0.524238  [  480/16250]\n",
      "loss: 0.534938  [  520/16250]\n",
      "loss: 0.550150  [  560/16250]\n",
      "loss: 0.575242  [  600/16250]\n",
      "loss: 0.532227  [  640/16250]\n",
      "loss: 0.561315  [  680/16250]\n",
      "loss: 0.551080  [  720/16250]\n",
      "loss: 0.567422  [  760/16250]\n",
      "loss: 0.555121  [  800/16250]\n",
      "loss: 0.545765  [  840/16250]\n",
      "loss: 0.560227  [  880/16250]\n",
      "loss: 0.543704  [  920/16250]\n",
      "loss: 0.538960  [  960/16250]\n",
      "loss: 0.542529  [ 1000/16250]\n",
      "loss: 0.576458  [ 1040/16250]\n",
      "loss: 0.554732  [ 1080/16250]\n",
      "loss: 0.553038  [ 1120/16250]\n",
      "loss: 0.529402  [ 1160/16250]\n",
      "loss: 0.541736  [ 1200/16250]\n",
      "loss: 0.551716  [ 1240/16250]\n",
      "loss: 0.557052  [ 1280/16250]\n",
      "loss: 0.566335  [ 1320/16250]\n",
      "loss: 0.540491  [ 1360/16250]\n",
      "loss: 0.559671  [ 1400/16250]\n",
      "loss: 0.570440  [ 1440/16250]\n",
      "loss: 0.537498  [ 1480/16250]\n",
      "loss: 0.551888  [ 1520/16250]\n",
      "loss: 0.561053  [ 1560/16250]\n",
      "loss: 0.549459  [ 1600/16250]\n",
      "loss: 0.557004  [ 1640/16250]\n",
      "loss: 0.560764  [ 1680/16250]\n",
      "loss: 0.560525  [ 1720/16250]\n",
      "loss: 0.571914  [ 1760/16250]\n",
      "loss: 0.553677  [ 1800/16250]\n",
      "loss: 0.548037  [ 1840/16250]\n",
      "loss: 0.535035  [ 1880/16250]\n",
      "loss: 0.574087  [ 1920/16250]\n",
      "loss: 0.554282  [ 1960/16250]\n",
      "loss: 0.560714  [ 2000/16250]\n",
      "loss: 0.543764  [ 2040/16250]\n",
      "loss: 0.556792  [ 2080/16250]\n",
      "loss: 0.567177  [ 2120/16250]\n",
      "loss: 0.558425  [ 2160/16250]\n",
      "loss: 0.548638  [ 2200/16250]\n",
      "loss: 0.544441  [ 2240/16250]\n",
      "loss: 0.545752  [ 2280/16250]\n",
      "loss: 0.557274  [ 2320/16250]\n",
      "loss: 0.556709  [ 2360/16250]\n",
      "loss: 0.555872  [ 2400/16250]\n",
      "loss: 0.552331  [ 2440/16250]\n",
      "loss: 0.540246  [ 2480/16250]\n",
      "loss: 0.541743  [ 2520/16250]\n",
      "loss: 0.543317  [ 2560/16250]\n",
      "loss: 0.555385  [ 2600/16250]\n",
      "loss: 0.538119  [ 2640/16250]\n",
      "loss: 0.554877  [ 2680/16250]\n",
      "loss: 0.556700  [ 2720/16250]\n",
      "loss: 0.550911  [ 2760/16250]\n",
      "loss: 0.582663  [ 2800/16250]\n",
      "loss: 0.566522  [ 2840/16250]\n",
      "loss: 0.562930  [ 2880/16250]\n",
      "loss: 0.549179  [ 2920/16250]\n",
      "loss: 0.574038  [ 2960/16250]\n",
      "loss: 0.550238  [ 3000/16250]\n",
      "loss: 0.558763  [ 3040/16250]\n",
      "loss: 0.542624  [ 3080/16250]\n",
      "loss: 0.535897  [ 3120/16250]\n",
      "loss: 0.537435  [ 3160/16250]\n",
      "loss: 0.558113  [ 3200/16250]\n",
      "loss: 0.544829  [ 3240/16250]\n",
      "loss: 0.561358  [ 3280/16250]\n",
      "loss: 0.555380  [ 3320/16250]\n",
      "loss: 0.571297  [ 3360/16250]\n",
      "loss: 0.550694  [ 3400/16250]\n",
      "loss: 0.535908  [ 3440/16250]\n",
      "loss: 0.555646  [ 3480/16250]\n",
      "loss: 0.565637  [ 3520/16250]\n",
      "loss: 0.570640  [ 3560/16250]\n",
      "loss: 0.541773  [ 3600/16250]\n",
      "loss: 0.568255  [ 3640/16250]\n",
      "loss: 0.543380  [ 3680/16250]\n",
      "loss: 0.530495  [ 3720/16250]\n",
      "loss: 0.553771  [ 3760/16250]\n",
      "loss: 0.548105  [ 3800/16250]\n",
      "loss: 0.547745  [ 3840/16250]\n",
      "loss: 0.557649  [ 3880/16250]\n",
      "loss: 0.555529  [ 3920/16250]\n",
      "loss: 0.542718  [ 3960/16250]\n",
      "loss: 0.565014  [ 4000/16250]\n",
      "loss: 0.538702  [ 4040/16250]\n",
      "loss: 0.567029  [ 4080/16250]\n",
      "loss: 0.582077  [ 4120/16250]\n",
      "loss: 0.535953  [ 4160/16250]\n",
      "loss: 0.535246  [ 4200/16250]\n",
      "loss: 0.549627  [ 4240/16250]\n",
      "loss: 0.581453  [ 4280/16250]\n",
      "loss: 0.539964  [ 4320/16250]\n",
      "loss: 0.556911  [ 4360/16250]\n",
      "loss: 0.567905  [ 4400/16250]\n",
      "loss: 0.577832  [ 4440/16250]\n",
      "loss: 0.548635  [ 4480/16250]\n",
      "loss: 0.555191  [ 4520/16250]\n",
      "loss: 0.551253  [ 4560/16250]\n",
      "loss: 0.565450  [ 4600/16250]\n",
      "loss: 0.557827  [ 4640/16250]\n",
      "loss: 0.557232  [ 4680/16250]\n",
      "loss: 0.564805  [ 4720/16250]\n",
      "loss: 0.571958  [ 4760/16250]\n",
      "loss: 0.574560  [ 4800/16250]\n",
      "loss: 0.551359  [ 4840/16250]\n",
      "loss: 0.552341  [ 4880/16250]\n",
      "loss: 0.527746  [ 4920/16250]\n",
      "loss: 0.549575  [ 4960/16250]\n",
      "loss: 0.535368  [ 5000/16250]\n",
      "loss: 0.561280  [ 5040/16250]\n",
      "loss: 0.535937  [ 5080/16250]\n",
      "loss: 0.548138  [ 5120/16250]\n",
      "loss: 0.535937  [ 5160/16250]\n",
      "loss: 0.559382  [ 5200/16250]\n",
      "loss: 0.551749  [ 5240/16250]\n",
      "loss: 0.565797  [ 5280/16250]\n",
      "loss: 0.540110  [ 5320/16250]\n",
      "loss: 0.544817  [ 5360/16250]\n",
      "loss: 0.545092  [ 5400/16250]\n",
      "loss: 0.552237  [ 5440/16250]\n",
      "loss: 0.544274  [ 5480/16250]\n",
      "loss: 0.543384  [ 5520/16250]\n",
      "loss: 0.557728  [ 5560/16250]\n",
      "loss: 0.561076  [ 5600/16250]\n",
      "loss: 0.546685  [ 5640/16250]\n",
      "loss: 0.536810  [ 5680/16250]\n",
      "loss: 0.555281  [ 5720/16250]\n",
      "loss: 0.571068  [ 5760/16250]\n",
      "loss: 0.558230  [ 5800/16250]\n",
      "loss: 0.563431  [ 5840/16250]\n",
      "loss: 0.549912  [ 5880/16250]\n",
      "loss: 0.578747  [ 5920/16250]\n",
      "loss: 0.533532  [ 5960/16250]\n",
      "loss: 0.553822  [ 6000/16250]\n",
      "loss: 0.562116  [ 6040/16250]\n",
      "loss: 0.540595  [ 6080/16250]\n",
      "loss: 0.538989  [ 6120/16250]\n",
      "loss: 0.537505  [ 6160/16250]\n",
      "loss: 0.545276  [ 6200/16250]\n",
      "loss: 0.559914  [ 6240/16250]\n",
      "loss: 0.562507  [ 6280/16250]\n",
      "loss: 0.553599  [ 6320/16250]\n",
      "loss: 0.561283  [ 6360/16250]\n",
      "loss: 0.559390  [ 6400/16250]\n",
      "loss: 0.561096  [ 6440/16250]\n",
      "loss: 0.556334  [ 6480/16250]\n",
      "loss: 0.528702  [ 6520/16250]\n",
      "loss: 0.537138  [ 6560/16250]\n",
      "loss: 0.533321  [ 6600/16250]\n",
      "loss: 0.560769  [ 6640/16250]\n",
      "loss: 0.556746  [ 6680/16250]\n",
      "loss: 0.558644  [ 6720/16250]\n",
      "loss: 0.559382  [ 6760/16250]\n",
      "loss: 0.576497  [ 6800/16250]\n",
      "loss: 0.555423  [ 6840/16250]\n",
      "loss: 0.538945  [ 6880/16250]\n",
      "loss: 0.567944  [ 6920/16250]\n",
      "loss: 0.546639  [ 6960/16250]\n",
      "loss: 0.536139  [ 7000/16250]\n",
      "loss: 0.564213  [ 7040/16250]\n",
      "loss: 0.551831  [ 7080/16250]\n",
      "loss: 0.549689  [ 7120/16250]\n",
      "loss: 0.551773  [ 7160/16250]\n",
      "loss: 0.553356  [ 7200/16250]\n",
      "loss: 0.545601  [ 7240/16250]\n",
      "loss: 0.530951  [ 7280/16250]\n",
      "loss: 0.552590  [ 7320/16250]\n",
      "loss: 0.554291  [ 7360/16250]\n",
      "loss: 0.566299  [ 7400/16250]\n",
      "loss: 0.594123  [ 7440/16250]\n",
      "loss: 0.579683  [ 7480/16250]\n",
      "loss: 0.535527  [ 7520/16250]\n",
      "loss: 0.564837  [ 7560/16250]\n",
      "loss: 0.533525  [ 7600/16250]\n",
      "loss: 0.561620  [ 7640/16250]\n",
      "loss: 0.559633  [ 7680/16250]\n",
      "loss: 0.568351  [ 7720/16250]\n",
      "loss: 0.545275  [ 7760/16250]\n",
      "loss: 0.548430  [ 7800/16250]\n",
      "loss: 0.564216  [ 7840/16250]\n",
      "loss: 0.559327  [ 7880/16250]\n",
      "loss: 0.559218  [ 7920/16250]\n",
      "loss: 0.561325  [ 7960/16250]\n",
      "loss: 0.547975  [ 8000/16250]\n",
      "loss: 0.533645  [ 8040/16250]\n",
      "loss: 0.544285  [ 8080/16250]\n",
      "loss: 0.565675  [ 8120/16250]\n",
      "loss: 0.580090  [ 8160/16250]\n",
      "loss: 0.549472  [ 8200/16250]\n",
      "loss: 0.558652  [ 8240/16250]\n",
      "loss: 0.561830  [ 8280/16250]\n",
      "loss: 0.577762  [ 8320/16250]\n",
      "loss: 0.541561  [ 8360/16250]\n",
      "loss: 0.550931  [ 8400/16250]\n",
      "loss: 0.544620  [ 8440/16250]\n",
      "loss: 0.515677  [ 8480/16250]\n",
      "loss: 0.552392  [ 8520/16250]\n",
      "loss: 0.568841  [ 8560/16250]\n",
      "loss: 0.537812  [ 8600/16250]\n",
      "loss: 0.555359  [ 8640/16250]\n",
      "loss: 0.551156  [ 8680/16250]\n",
      "loss: 0.558160  [ 8720/16250]\n",
      "loss: 0.543789  [ 8760/16250]\n",
      "loss: 0.554274  [ 8800/16250]\n",
      "loss: 0.547270  [ 8840/16250]\n",
      "loss: 0.532520  [ 8880/16250]\n",
      "loss: 0.536749  [ 8920/16250]\n",
      "loss: 0.539636  [ 8960/16250]\n",
      "loss: 0.540162  [ 9000/16250]\n",
      "loss: 0.565162  [ 9040/16250]\n",
      "loss: 0.541444  [ 9080/16250]\n",
      "loss: 0.550970  [ 9120/16250]\n",
      "loss: 0.545227  [ 9160/16250]\n",
      "loss: 0.561149  [ 9200/16250]\n",
      "loss: 0.549438  [ 9240/16250]\n",
      "loss: 0.539178  [ 9280/16250]\n",
      "loss: 0.543717  [ 9320/16250]\n",
      "loss: 0.564935  [ 9360/16250]\n",
      "loss: 0.552805  [ 9400/16250]\n",
      "loss: 0.555828  [ 9440/16250]\n",
      "loss: 0.581210  [ 9480/16250]\n",
      "loss: 0.573837  [ 9520/16250]\n",
      "loss: 0.542786  [ 9560/16250]\n",
      "loss: 0.560647  [ 9600/16250]\n",
      "loss: 0.533802  [ 9640/16250]\n",
      "loss: 0.564888  [ 9680/16250]\n",
      "loss: 0.542469  [ 9720/16250]\n",
      "loss: 0.547828  [ 9760/16250]\n",
      "loss: 0.534020  [ 9800/16250]\n",
      "loss: 0.555064  [ 9840/16250]\n",
      "loss: 0.559964  [ 9880/16250]\n",
      "loss: 0.577175  [ 9920/16250]\n",
      "loss: 0.568990  [ 9960/16250]\n",
      "loss: 0.570137  [10000/16250]\n",
      "loss: 0.545447  [10040/16250]\n",
      "loss: 0.550580  [10080/16250]\n",
      "loss: 0.542362  [10120/16250]\n",
      "loss: 0.562315  [10160/16250]\n",
      "loss: 0.561035  [10200/16250]\n",
      "loss: 0.555068  [10240/16250]\n",
      "loss: 0.573893  [10280/16250]\n",
      "loss: 0.558590  [10320/16250]\n",
      "loss: 0.558001  [10360/16250]\n",
      "loss: 0.557972  [10400/16250]\n",
      "loss: 0.550782  [10440/16250]\n",
      "loss: 0.554077  [10480/16250]\n",
      "loss: 0.541780  [10520/16250]\n",
      "loss: 0.549402  [10560/16250]\n",
      "loss: 0.544348  [10600/16250]\n",
      "loss: 0.538094  [10640/16250]\n",
      "loss: 0.564978  [10680/16250]\n",
      "loss: 0.554377  [10720/16250]\n",
      "loss: 0.526590  [10760/16250]\n",
      "loss: 0.549573  [10800/16250]\n",
      "loss: 0.543663  [10840/16250]\n",
      "loss: 0.561346  [10880/16250]\n",
      "loss: 0.536805  [10920/16250]\n",
      "loss: 0.574574  [10960/16250]\n",
      "loss: 0.564323  [11000/16250]\n",
      "loss: 0.549469  [11040/16250]\n",
      "loss: 0.562997  [11080/16250]\n",
      "loss: 0.555849  [11120/16250]\n",
      "loss: 0.528879  [11160/16250]\n",
      "loss: 0.536555  [11200/16250]\n",
      "loss: 0.554528  [11240/16250]\n",
      "loss: 0.589958  [11280/16250]\n",
      "loss: 0.544122  [11320/16250]\n",
      "loss: 0.549046  [11360/16250]\n",
      "loss: 0.539714  [11400/16250]\n",
      "loss: 0.570691  [11440/16250]\n",
      "loss: 0.548047  [11480/16250]\n",
      "loss: 0.538762  [11520/16250]\n",
      "loss: 0.529991  [11560/16250]\n",
      "loss: 0.547598  [11600/16250]\n",
      "loss: 0.544622  [11640/16250]\n",
      "loss: 0.541633  [11680/16250]\n",
      "loss: 0.542919  [11720/16250]\n",
      "loss: 0.567270  [11760/16250]\n",
      "loss: 0.572903  [11800/16250]\n",
      "loss: 0.538409  [11840/16250]\n",
      "loss: 0.572738  [11880/16250]\n",
      "loss: 0.555011  [11920/16250]\n",
      "loss: 0.573971  [11960/16250]\n",
      "loss: 0.559993  [12000/16250]\n",
      "loss: 0.536151  [12040/16250]\n",
      "loss: 0.542373  [12080/16250]\n",
      "loss: 0.547287  [12120/16250]\n",
      "loss: 0.559841  [12160/16250]\n",
      "loss: 0.551770  [12200/16250]\n",
      "loss: 0.549772  [12240/16250]\n",
      "loss: 0.561778  [12280/16250]\n",
      "loss: 0.542280  [12320/16250]\n",
      "loss: 0.549936  [12360/16250]\n",
      "loss: 0.561177  [12400/16250]\n",
      "loss: 0.542085  [12440/16250]\n",
      "loss: 0.565325  [12480/16250]\n",
      "loss: 0.533674  [12520/16250]\n",
      "loss: 0.559375  [12560/16250]\n",
      "loss: 0.538712  [12600/16250]\n",
      "loss: 0.559968  [12640/16250]\n",
      "loss: 0.540742  [12680/16250]\n",
      "loss: 0.536093  [12720/16250]\n",
      "loss: 0.574488  [12760/16250]\n",
      "loss: 0.540309  [12800/16250]\n",
      "loss: 0.550838  [12840/16250]\n",
      "loss: 0.576675  [12880/16250]\n",
      "loss: 0.549959  [12920/16250]\n",
      "loss: 0.570727  [12960/16250]\n",
      "loss: 0.559076  [13000/16250]\n",
      "loss: 0.555520  [13040/16250]\n",
      "loss: 0.548921  [13080/16250]\n",
      "loss: 0.534970  [13120/16250]\n",
      "loss: 0.549770  [13160/16250]\n",
      "loss: 0.545059  [13200/16250]\n",
      "loss: 0.557568  [13240/16250]\n",
      "loss: 0.562487  [13280/16250]\n",
      "loss: 0.566757  [13320/16250]\n",
      "loss: 0.558854  [13360/16250]\n",
      "loss: 0.549092  [13400/16250]\n",
      "loss: 0.550949  [13440/16250]\n",
      "loss: 0.548132  [13480/16250]\n",
      "loss: 0.555362  [13520/16250]\n",
      "loss: 0.544464  [13560/16250]\n",
      "loss: 0.553896  [13600/16250]\n",
      "loss: 0.540732  [13640/16250]\n",
      "loss: 0.561786  [13680/16250]\n",
      "loss: 0.553370  [13720/16250]\n",
      "loss: 0.542943  [13760/16250]\n",
      "loss: 0.552930  [13800/16250]\n",
      "loss: 0.554837  [13840/16250]\n",
      "loss: 0.544059  [13880/16250]\n",
      "loss: 0.541603  [13920/16250]\n",
      "loss: 0.538423  [13960/16250]\n",
      "loss: 0.558423  [14000/16250]\n",
      "loss: 0.533407  [14040/16250]\n",
      "loss: 0.555724  [14080/16250]\n",
      "loss: 0.566912  [14120/16250]\n",
      "loss: 0.560489  [14160/16250]\n",
      "loss: 0.546381  [14200/16250]\n",
      "loss: 0.547145  [14240/16250]\n",
      "loss: 0.560983  [14280/16250]\n",
      "loss: 0.567998  [14320/16250]\n",
      "loss: 0.535983  [14360/16250]\n",
      "loss: 0.573376  [14400/16250]\n",
      "loss: 0.556205  [14440/16250]\n",
      "loss: 0.557144  [14480/16250]\n",
      "loss: 0.541187  [14520/16250]\n",
      "loss: 0.534608  [14560/16250]\n",
      "loss: 0.553114  [14600/16250]\n",
      "loss: 0.568770  [14640/16250]\n",
      "loss: 0.570552  [14680/16250]\n",
      "loss: 0.551199  [14720/16250]\n",
      "loss: 0.537842  [14760/16250]\n",
      "loss: 0.550339  [14800/16250]\n",
      "loss: 0.541021  [14840/16250]\n",
      "loss: 0.551949  [14880/16250]\n",
      "loss: 0.564257  [14920/16250]\n",
      "loss: 0.548936  [14960/16250]\n",
      "loss: 0.542181  [15000/16250]\n",
      "loss: 0.556942  [15040/16250]\n",
      "loss: 0.554700  [15080/16250]\n",
      "loss: 0.566774  [15120/16250]\n",
      "loss: 0.546588  [15160/16250]\n",
      "loss: 0.538333  [15200/16250]\n",
      "loss: 0.538250  [15240/16250]\n",
      "loss: 0.554712  [15280/16250]\n",
      "loss: 0.547474  [15320/16250]\n",
      "loss: 0.546720  [15360/16250]\n",
      "loss: 0.533228  [15400/16250]\n",
      "loss: 0.554003  [15440/16250]\n",
      "loss: 0.549397  [15480/16250]\n",
      "loss: 0.523923  [15520/16250]\n",
      "loss: 0.549360  [15560/16250]\n",
      "loss: 0.534701  [15600/16250]\n",
      "loss: 0.540536  [15640/16250]\n",
      "loss: 0.553879  [15680/16250]\n",
      "loss: 0.552595  [15720/16250]\n",
      "loss: 0.547433  [15760/16250]\n",
      "loss: 0.549752  [15800/16250]\n",
      "loss: 0.570875  [15840/16250]\n",
      "loss: 0.552087  [15880/16250]\n",
      "loss: 0.541235  [15920/16250]\n",
      "loss: 0.520026  [15960/16250]\n",
      "loss: 0.560814  [16000/16250]\n",
      "loss: 0.553030  [16040/16250]\n",
      "loss: 0.552427  [16080/16250]\n",
      "loss: 0.539054  [16120/16250]\n",
      "loss: 0.552795  [16160/16250]\n",
      "loss: 0.565147  [16200/16250]\n",
      "loss: 0.584896  [ 8120/16250]\n",
      "Avg loss: 0.755668 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.556866  [    0/16250]\n",
      "loss: 0.537045  [   40/16250]\n",
      "loss: 0.516383  [   80/16250]\n",
      "loss: 0.547483  [  120/16250]\n",
      "loss: 0.554002  [  160/16250]\n",
      "loss: 0.557169  [  200/16250]\n",
      "loss: 0.564879  [  240/16250]\n",
      "loss: 0.530622  [  280/16250]\n",
      "loss: 0.533972  [  320/16250]\n",
      "loss: 0.554065  [  360/16250]\n",
      "loss: 0.532291  [  400/16250]\n",
      "loss: 0.532859  [  440/16250]\n",
      "loss: 0.540169  [  480/16250]\n",
      "loss: 0.547556  [  520/16250]\n",
      "loss: 0.533918  [  560/16250]\n",
      "loss: 0.533151  [  600/16250]\n",
      "loss: 0.540288  [  640/16250]\n",
      "loss: 0.550684  [  680/16250]\n",
      "loss: 0.531552  [  720/16250]\n",
      "loss: 0.558325  [  760/16250]\n",
      "loss: 0.547415  [  800/16250]\n",
      "loss: 0.536524  [  840/16250]\n",
      "loss: 0.537997  [  880/16250]\n",
      "loss: 0.528172  [  920/16250]\n",
      "loss: 0.542563  [  960/16250]\n",
      "loss: 0.554746  [ 1000/16250]\n",
      "loss: 0.546399  [ 1040/16250]\n",
      "loss: 0.551924  [ 1080/16250]\n",
      "loss: 0.511697  [ 1120/16250]\n",
      "loss: 0.570576  [ 1160/16250]\n",
      "loss: 0.554920  [ 1200/16250]\n",
      "loss: 0.524184  [ 1240/16250]\n",
      "loss: 0.541091  [ 1280/16250]\n",
      "loss: 0.535658  [ 1320/16250]\n",
      "loss: 0.562994  [ 1360/16250]\n",
      "loss: 0.558179  [ 1400/16250]\n",
      "loss: 0.532188  [ 1440/16250]\n",
      "loss: 0.540200  [ 1480/16250]\n",
      "loss: 0.537932  [ 1520/16250]\n",
      "loss: 0.528597  [ 1560/16250]\n",
      "loss: 0.541587  [ 1600/16250]\n",
      "loss: 0.528722  [ 1640/16250]\n",
      "loss: 0.546344  [ 1680/16250]\n",
      "loss: 0.538196  [ 1720/16250]\n",
      "loss: 0.544178  [ 1760/16250]\n",
      "loss: 0.534177  [ 1800/16250]\n",
      "loss: 0.560367  [ 1840/16250]\n",
      "loss: 0.558738  [ 1880/16250]\n",
      "loss: 0.519940  [ 1920/16250]\n",
      "loss: 0.538018  [ 1960/16250]\n",
      "loss: 0.522249  [ 2000/16250]\n",
      "loss: 0.528117  [ 2040/16250]\n",
      "loss: 0.551778  [ 2080/16250]\n",
      "loss: 0.545344  [ 2120/16250]\n",
      "loss: 0.523701  [ 2160/16250]\n",
      "loss: 0.543658  [ 2200/16250]\n",
      "loss: 0.546805  [ 2240/16250]\n",
      "loss: 0.531411  [ 2280/16250]\n",
      "loss: 0.548466  [ 2320/16250]\n",
      "loss: 0.572350  [ 2360/16250]\n",
      "loss: 0.528086  [ 2400/16250]\n",
      "loss: 0.525862  [ 2440/16250]\n",
      "loss: 0.537017  [ 2480/16250]\n",
      "loss: 0.535394  [ 2520/16250]\n",
      "loss: 0.544429  [ 2560/16250]\n",
      "loss: 0.540062  [ 2600/16250]\n",
      "loss: 0.534104  [ 2640/16250]\n",
      "loss: 0.533227  [ 2680/16250]\n",
      "loss: 0.529888  [ 2720/16250]\n",
      "loss: 0.536906  [ 2760/16250]\n",
      "loss: 0.518512  [ 2800/16250]\n",
      "loss: 0.568369  [ 2840/16250]\n",
      "loss: 0.553970  [ 2880/16250]\n",
      "loss: 0.535781  [ 2920/16250]\n",
      "loss: 0.563230  [ 2960/16250]\n",
      "loss: 0.549309  [ 3000/16250]\n",
      "loss: 0.542953  [ 3040/16250]\n",
      "loss: 0.534035  [ 3080/16250]\n",
      "loss: 0.546403  [ 3120/16250]\n",
      "loss: 0.541628  [ 3160/16250]\n",
      "loss: 0.534499  [ 3200/16250]\n",
      "loss: 0.548999  [ 3240/16250]\n",
      "loss: 0.553345  [ 3280/16250]\n",
      "loss: 0.532025  [ 3320/16250]\n",
      "loss: 0.565697  [ 3360/16250]\n",
      "loss: 0.523439  [ 3400/16250]\n",
      "loss: 0.568959  [ 3440/16250]\n",
      "loss: 0.548975  [ 3480/16250]\n",
      "loss: 0.538641  [ 3520/16250]\n",
      "loss: 0.540193  [ 3560/16250]\n",
      "loss: 0.549416  [ 3600/16250]\n",
      "loss: 0.548908  [ 3640/16250]\n",
      "loss: 0.546830  [ 3680/16250]\n",
      "loss: 0.549154  [ 3720/16250]\n",
      "loss: 0.542561  [ 3760/16250]\n",
      "loss: 0.549387  [ 3800/16250]\n",
      "loss: 0.532949  [ 3840/16250]\n",
      "loss: 0.550866  [ 3880/16250]\n",
      "loss: 0.523332  [ 3920/16250]\n",
      "loss: 0.536688  [ 3960/16250]\n",
      "loss: 0.531733  [ 4000/16250]\n",
      "loss: 0.538739  [ 4040/16250]\n",
      "loss: 0.513786  [ 4080/16250]\n",
      "loss: 0.544153  [ 4120/16250]\n",
      "loss: 0.547409  [ 4160/16250]\n",
      "loss: 0.527627  [ 4200/16250]\n",
      "loss: 0.532458  [ 4240/16250]\n",
      "loss: 0.554200  [ 4280/16250]\n",
      "loss: 0.541564  [ 4320/16250]\n",
      "loss: 0.544303  [ 4360/16250]\n",
      "loss: 0.526577  [ 4400/16250]\n",
      "loss: 0.545585  [ 4440/16250]\n",
      "loss: 0.541114  [ 4480/16250]\n",
      "loss: 0.545670  [ 4520/16250]\n",
      "loss: 0.525912  [ 4560/16250]\n",
      "loss: 0.545523  [ 4600/16250]\n",
      "loss: 0.527161  [ 4640/16250]\n",
      "loss: 0.541411  [ 4680/16250]\n",
      "loss: 0.523819  [ 4720/16250]\n",
      "loss: 0.540926  [ 4760/16250]\n",
      "loss: 0.552138  [ 4800/16250]\n",
      "loss: 0.542196  [ 4840/16250]\n",
      "loss: 0.545589  [ 4880/16250]\n",
      "loss: 0.534857  [ 4920/16250]\n",
      "loss: 0.547554  [ 4960/16250]\n",
      "loss: 0.547018  [ 5000/16250]\n",
      "loss: 0.544567  [ 5040/16250]\n",
      "loss: 0.552626  [ 5080/16250]\n",
      "loss: 0.563105  [ 5120/16250]\n",
      "loss: 0.533783  [ 5160/16250]\n",
      "loss: 0.544913  [ 5200/16250]\n",
      "loss: 0.522557  [ 5240/16250]\n",
      "loss: 0.563933  [ 5280/16250]\n",
      "loss: 0.542169  [ 5320/16250]\n",
      "loss: 0.540619  [ 5360/16250]\n",
      "loss: 0.535964  [ 5400/16250]\n",
      "loss: 0.533298  [ 5440/16250]\n",
      "loss: 0.548701  [ 5480/16250]\n",
      "loss: 0.541487  [ 5520/16250]\n",
      "loss: 0.544694  [ 5560/16250]\n",
      "loss: 0.553113  [ 5600/16250]\n",
      "loss: 0.529313  [ 5640/16250]\n",
      "loss: 0.541933  [ 5680/16250]\n",
      "loss: 0.528997  [ 5720/16250]\n",
      "loss: 0.542204  [ 5760/16250]\n",
      "loss: 0.548190  [ 5800/16250]\n",
      "loss: 0.536911  [ 5840/16250]\n",
      "loss: 0.516947  [ 5880/16250]\n",
      "loss: 0.538071  [ 5920/16250]\n",
      "loss: 0.529924  [ 5960/16250]\n",
      "loss: 0.517441  [ 6000/16250]\n",
      "loss: 0.549492  [ 6040/16250]\n",
      "loss: 0.532424  [ 6080/16250]\n",
      "loss: 0.541717  [ 6120/16250]\n",
      "loss: 0.525053  [ 6160/16250]\n",
      "loss: 0.563534  [ 6200/16250]\n",
      "loss: 0.534129  [ 6240/16250]\n",
      "loss: 0.523463  [ 6280/16250]\n",
      "loss: 0.531970  [ 6320/16250]\n",
      "loss: 0.542424  [ 6360/16250]\n",
      "loss: 0.525607  [ 6400/16250]\n",
      "loss: 0.544630  [ 6440/16250]\n",
      "loss: 0.547693  [ 6480/16250]\n",
      "loss: 0.540327  [ 6520/16250]\n",
      "loss: 0.519421  [ 6560/16250]\n",
      "loss: 0.531808  [ 6600/16250]\n",
      "loss: 0.528419  [ 6640/16250]\n",
      "loss: 0.541285  [ 6680/16250]\n",
      "loss: 0.526238  [ 6720/16250]\n",
      "loss: 0.539359  [ 6760/16250]\n",
      "loss: 0.538812  [ 6800/16250]\n",
      "loss: 0.562037  [ 6840/16250]\n",
      "loss: 0.540955  [ 6880/16250]\n",
      "loss: 0.546909  [ 6920/16250]\n",
      "loss: 0.560237  [ 6960/16250]\n",
      "loss: 0.512099  [ 7000/16250]\n",
      "loss: 0.545978  [ 7040/16250]\n",
      "loss: 0.515531  [ 7080/16250]\n",
      "loss: 0.534447  [ 7120/16250]\n",
      "loss: 0.554807  [ 7160/16250]\n",
      "loss: 0.538109  [ 7200/16250]\n",
      "loss: 0.526513  [ 7240/16250]\n",
      "loss: 0.535017  [ 7280/16250]\n",
      "loss: 0.542625  [ 7320/16250]\n",
      "loss: 0.543997  [ 7360/16250]\n",
      "loss: 0.550930  [ 7400/16250]\n",
      "loss: 0.581573  [ 7440/16250]\n",
      "loss: 0.539494  [ 7480/16250]\n",
      "loss: 0.527078  [ 7520/16250]\n",
      "loss: 0.550008  [ 7560/16250]\n",
      "loss: 0.537800  [ 7600/16250]\n",
      "loss: 0.533727  [ 7640/16250]\n",
      "loss: 0.532225  [ 7680/16250]\n",
      "loss: 0.549147  [ 7720/16250]\n",
      "loss: 0.546539  [ 7760/16250]\n",
      "loss: 0.521244  [ 7800/16250]\n",
      "loss: 0.520928  [ 7840/16250]\n",
      "loss: 0.558344  [ 7880/16250]\n",
      "loss: 0.534183  [ 7920/16250]\n",
      "loss: 0.559083  [ 7960/16250]\n",
      "loss: 0.555217  [ 8000/16250]\n",
      "loss: 0.539051  [ 8040/16250]\n",
      "loss: 0.550387  [ 8080/16250]\n",
      "loss: 0.544721  [ 8120/16250]\n",
      "loss: 0.538374  [ 8160/16250]\n",
      "loss: 0.541434  [ 8200/16250]\n",
      "loss: 0.548319  [ 8240/16250]\n",
      "loss: 0.529318  [ 8280/16250]\n",
      "loss: 0.541294  [ 8320/16250]\n",
      "loss: 0.508189  [ 8360/16250]\n",
      "loss: 0.544580  [ 8400/16250]\n",
      "loss: 0.553548  [ 8440/16250]\n",
      "loss: 0.518801  [ 8480/16250]\n",
      "loss: 0.545739  [ 8520/16250]\n",
      "loss: 0.528697  [ 8560/16250]\n",
      "loss: 0.549860  [ 8600/16250]\n",
      "loss: 0.525326  [ 8640/16250]\n",
      "loss: 0.536274  [ 8680/16250]\n",
      "loss: 0.526892  [ 8720/16250]\n",
      "loss: 0.517143  [ 8760/16250]\n",
      "loss: 0.543255  [ 8800/16250]\n",
      "loss: 0.593127  [ 8840/16250]\n",
      "loss: 0.523767  [ 8880/16250]\n",
      "loss: 0.537659  [ 8920/16250]\n",
      "loss: 0.545299  [ 8960/16250]\n",
      "loss: 0.534091  [ 9000/16250]\n",
      "loss: 0.555106  [ 9040/16250]\n",
      "loss: 0.538493  [ 9080/16250]\n",
      "loss: 0.529200  [ 9120/16250]\n",
      "loss: 0.530677  [ 9160/16250]\n",
      "loss: 0.536188  [ 9200/16250]\n",
      "loss: 0.539630  [ 9240/16250]\n",
      "loss: 0.528006  [ 9280/16250]\n",
      "loss: 0.522115  [ 9320/16250]\n",
      "loss: 0.529621  [ 9360/16250]\n",
      "loss: 0.527813  [ 9400/16250]\n",
      "loss: 0.551900  [ 9440/16250]\n",
      "loss: 0.542052  [ 9480/16250]\n",
      "loss: 0.526832  [ 9520/16250]\n",
      "loss: 0.522234  [ 9560/16250]\n",
      "loss: 0.524303  [ 9600/16250]\n",
      "loss: 0.539036  [ 9640/16250]\n",
      "loss: 0.554579  [ 9680/16250]\n",
      "loss: 0.556428  [ 9720/16250]\n",
      "loss: 0.551349  [ 9760/16250]\n",
      "loss: 0.539472  [ 9800/16250]\n",
      "loss: 0.528020  [ 9840/16250]\n",
      "loss: 0.522009  [ 9880/16250]\n",
      "loss: 0.547604  [ 9920/16250]\n",
      "loss: 0.535599  [ 9960/16250]\n",
      "loss: 0.528122  [10000/16250]\n",
      "loss: 0.572369  [10040/16250]\n",
      "loss: 0.520944  [10080/16250]\n",
      "loss: 0.514267  [10120/16250]\n",
      "loss: 0.524379  [10160/16250]\n",
      "loss: 0.538092  [10200/16250]\n",
      "loss: 0.535797  [10240/16250]\n",
      "loss: 0.557435  [10280/16250]\n",
      "loss: 0.545916  [10320/16250]\n",
      "loss: 0.543201  [10360/16250]\n",
      "loss: 0.512677  [10400/16250]\n",
      "loss: 0.550161  [10440/16250]\n",
      "loss: 0.515848  [10480/16250]\n",
      "loss: 0.558440  [10520/16250]\n",
      "loss: 0.558281  [10560/16250]\n",
      "loss: 0.520589  [10600/16250]\n",
      "loss: 0.562252  [10640/16250]\n",
      "loss: 0.549124  [10680/16250]\n",
      "loss: 0.538193  [10720/16250]\n",
      "loss: 0.526616  [10760/16250]\n",
      "loss: 0.543370  [10800/16250]\n",
      "loss: 0.543908  [10840/16250]\n",
      "loss: 0.591921  [10880/16250]\n",
      "loss: 0.549228  [10920/16250]\n",
      "loss: 0.534828  [10960/16250]\n",
      "loss: 0.548234  [11000/16250]\n",
      "loss: 0.527955  [11040/16250]\n",
      "loss: 0.529395  [11080/16250]\n",
      "loss: 0.551308  [11120/16250]\n",
      "loss: 0.523941  [11160/16250]\n",
      "loss: 0.563789  [11200/16250]\n",
      "loss: 0.540778  [11240/16250]\n",
      "loss: 0.522414  [11280/16250]\n",
      "loss: 0.568798  [11320/16250]\n",
      "loss: 0.555030  [11360/16250]\n",
      "loss: 0.521409  [11400/16250]\n",
      "loss: 0.526825  [11440/16250]\n",
      "loss: 0.539270  [11480/16250]\n",
      "loss: 0.545219  [11520/16250]\n",
      "loss: 0.526866  [11560/16250]\n",
      "loss: 0.544676  [11600/16250]\n",
      "loss: 0.538395  [11640/16250]\n",
      "loss: 0.536956  [11680/16250]\n",
      "loss: 0.516752  [11720/16250]\n",
      "loss: 0.536049  [11760/16250]\n",
      "loss: 0.542895  [11800/16250]\n",
      "loss: 0.555896  [11840/16250]\n",
      "loss: 0.515429  [11880/16250]\n",
      "loss: 0.541551  [11920/16250]\n",
      "loss: 0.534171  [11960/16250]\n",
      "loss: 0.525774  [12000/16250]\n",
      "loss: 0.507497  [12040/16250]\n",
      "loss: 0.550581  [12080/16250]\n",
      "loss: 0.550690  [12120/16250]\n",
      "loss: 0.549967  [12160/16250]\n",
      "loss: 0.516311  [12200/16250]\n",
      "loss: 0.533054  [12240/16250]\n",
      "loss: 0.536694  [12280/16250]\n",
      "loss: 0.550330  [12320/16250]\n",
      "loss: 0.535826  [12360/16250]\n",
      "loss: 0.524915  [12400/16250]\n",
      "loss: 0.516199  [12440/16250]\n",
      "loss: 0.531450  [12480/16250]\n",
      "loss: 0.563079  [12520/16250]\n",
      "loss: 0.551545  [12560/16250]\n",
      "loss: 0.537765  [12600/16250]\n",
      "loss: 0.534523  [12640/16250]\n",
      "loss: 0.522360  [12680/16250]\n",
      "loss: 0.527131  [12720/16250]\n",
      "loss: 0.534578  [12760/16250]\n",
      "loss: 0.545344  [12800/16250]\n",
      "loss: 0.527717  [12840/16250]\n",
      "loss: 0.525009  [12880/16250]\n",
      "loss: 0.544795  [12920/16250]\n",
      "loss: 0.525701  [12960/16250]\n",
      "loss: 0.574503  [13000/16250]\n",
      "loss: 0.529166  [13040/16250]\n",
      "loss: 0.516203  [13080/16250]\n",
      "loss: 0.553423  [13120/16250]\n",
      "loss: 0.520241  [13160/16250]\n",
      "loss: 0.518623  [13200/16250]\n",
      "loss: 0.528835  [13240/16250]\n",
      "loss: 0.557640  [13280/16250]\n",
      "loss: 0.556562  [13320/16250]\n",
      "loss: 0.575563  [13360/16250]\n",
      "loss: 0.534767  [13400/16250]\n",
      "loss: 0.537725  [13440/16250]\n",
      "loss: 0.532531  [13480/16250]\n",
      "loss: 0.529615  [13520/16250]\n",
      "loss: 0.541102  [13560/16250]\n",
      "loss: 0.555108  [13600/16250]\n",
      "loss: 0.532652  [13640/16250]\n",
      "loss: 0.559399  [13680/16250]\n",
      "loss: 0.534197  [13720/16250]\n",
      "loss: 0.553643  [13760/16250]\n",
      "loss: 0.514954  [13800/16250]\n",
      "loss: 0.529800  [13840/16250]\n",
      "loss: 0.566189  [13880/16250]\n",
      "loss: 0.541040  [13920/16250]\n",
      "loss: 0.544976  [13960/16250]\n",
      "loss: 0.528266  [14000/16250]\n",
      "loss: 0.552356  [14040/16250]\n",
      "loss: 0.530351  [14080/16250]\n",
      "loss: 0.528674  [14120/16250]\n",
      "loss: 0.530977  [14160/16250]\n",
      "loss: 0.540203  [14200/16250]\n",
      "loss: 0.525762  [14240/16250]\n",
      "loss: 0.525578  [14280/16250]\n",
      "loss: 0.538326  [14320/16250]\n",
      "loss: 0.551667  [14360/16250]\n",
      "loss: 0.520826  [14400/16250]\n",
      "loss: 0.536408  [14440/16250]\n",
      "loss: 0.550085  [14480/16250]\n",
      "loss: 0.553335  [14520/16250]\n",
      "loss: 0.539725  [14560/16250]\n",
      "loss: 0.550619  [14600/16250]\n",
      "loss: 0.538943  [14640/16250]\n",
      "loss: 0.541633  [14680/16250]\n",
      "loss: 0.525783  [14720/16250]\n",
      "loss: 0.532668  [14760/16250]\n",
      "loss: 0.537354  [14800/16250]\n",
      "loss: 0.532804  [14840/16250]\n",
      "loss: 0.529183  [14880/16250]\n",
      "loss: 0.562419  [14920/16250]\n",
      "loss: 0.536092  [14960/16250]\n",
      "loss: 0.528505  [15000/16250]\n",
      "loss: 0.527821  [15040/16250]\n",
      "loss: 0.550189  [15080/16250]\n",
      "loss: 0.545899  [15120/16250]\n",
      "loss: 0.537282  [15160/16250]\n",
      "loss: 0.534827  [15200/16250]\n",
      "loss: 0.556891  [15240/16250]\n",
      "loss: 0.534443  [15280/16250]\n",
      "loss: 0.546789  [15320/16250]\n",
      "loss: 0.528170  [15360/16250]\n",
      "loss: 0.518714  [15400/16250]\n",
      "loss: 0.532651  [15440/16250]\n",
      "loss: 0.538378  [15480/16250]\n",
      "loss: 0.523468  [15520/16250]\n",
      "loss: 0.524422  [15560/16250]\n",
      "loss: 0.555233  [15600/16250]\n",
      "loss: 0.546299  [15640/16250]\n",
      "loss: 0.539268  [15680/16250]\n",
      "loss: 0.536108  [15720/16250]\n",
      "loss: 0.535789  [15760/16250]\n",
      "loss: 0.542431  [15800/16250]\n",
      "loss: 0.528204  [15840/16250]\n",
      "loss: 0.538788  [15880/16250]\n",
      "loss: 0.537086  [15920/16250]\n",
      "loss: 0.516045  [15960/16250]\n",
      "loss: 0.565676  [16000/16250]\n",
      "loss: 0.541405  [16040/16250]\n",
      "loss: 0.537046  [16080/16250]\n",
      "loss: 0.521575  [16120/16250]\n",
      "loss: 0.532985  [16160/16250]\n",
      "loss: 0.533836  [16200/16250]\n",
      "loss: 0.533656  [ 8120/16250]\n",
      "Avg loss: 0.792618 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.532532  [    0/16250]\n",
      "loss: 0.523066  [   40/16250]\n",
      "loss: 0.525106  [   80/16250]\n",
      "loss: 0.521861  [  120/16250]\n",
      "loss: 0.533616  [  160/16250]\n",
      "loss: 0.537770  [  200/16250]\n",
      "loss: 0.544368  [  240/16250]\n",
      "loss: 0.519089  [  280/16250]\n",
      "loss: 0.538361  [  320/16250]\n",
      "loss: 0.530666  [  360/16250]\n",
      "loss: 0.519603  [  400/16250]\n",
      "loss: 0.538355  [  440/16250]\n",
      "loss: 0.516946  [  480/16250]\n",
      "loss: 0.537870  [  520/16250]\n",
      "loss: 0.510831  [  560/16250]\n",
      "loss: 0.544866  [  600/16250]\n",
      "loss: 0.502551  [  640/16250]\n",
      "loss: 0.522204  [  680/16250]\n",
      "loss: 0.531494  [  720/16250]\n",
      "loss: 0.534534  [  760/16250]\n",
      "loss: 0.530776  [  800/16250]\n",
      "loss: 0.519306  [  840/16250]\n",
      "loss: 0.527088  [  880/16250]\n",
      "loss: 0.518286  [  920/16250]\n",
      "loss: 0.525491  [  960/16250]\n",
      "loss: 0.554146  [ 1000/16250]\n",
      "loss: 0.521683  [ 1040/16250]\n",
      "loss: 0.524696  [ 1080/16250]\n",
      "loss: 0.529626  [ 1120/16250]\n",
      "loss: 0.546723  [ 1160/16250]\n",
      "loss: 0.523895  [ 1200/16250]\n",
      "loss: 0.495439  [ 1240/16250]\n",
      "loss: 0.533554  [ 1280/16250]\n",
      "loss: 0.533166  [ 1320/16250]\n",
      "loss: 0.503551  [ 1360/16250]\n",
      "loss: 0.532091  [ 1400/16250]\n",
      "loss: 0.533664  [ 1440/16250]\n",
      "loss: 0.512919  [ 1480/16250]\n",
      "loss: 0.540315  [ 1520/16250]\n",
      "loss: 0.564181  [ 1560/16250]\n",
      "loss: 0.522533  [ 1600/16250]\n",
      "loss: 0.528734  [ 1640/16250]\n",
      "loss: 0.517023  [ 1680/16250]\n",
      "loss: 0.519379  [ 1720/16250]\n",
      "loss: 0.516525  [ 1760/16250]\n",
      "loss: 0.521573  [ 1800/16250]\n",
      "loss: 0.539882  [ 1840/16250]\n",
      "loss: 0.519345  [ 1880/16250]\n",
      "loss: 0.529367  [ 1920/16250]\n",
      "loss: 0.519112  [ 1960/16250]\n",
      "loss: 0.529799  [ 2000/16250]\n",
      "loss: 0.506645  [ 2040/16250]\n",
      "loss: 0.523474  [ 2080/16250]\n",
      "loss: 0.547338  [ 2120/16250]\n",
      "loss: 0.524098  [ 2160/16250]\n",
      "loss: 0.529855  [ 2200/16250]\n",
      "loss: 0.524956  [ 2240/16250]\n",
      "loss: 0.532121  [ 2280/16250]\n",
      "loss: 0.517028  [ 2320/16250]\n",
      "loss: 0.551465  [ 2360/16250]\n",
      "loss: 0.543771  [ 2400/16250]\n",
      "loss: 0.527625  [ 2440/16250]\n",
      "loss: 0.543755  [ 2480/16250]\n",
      "loss: 0.526520  [ 2520/16250]\n",
      "loss: 0.540914  [ 2560/16250]\n",
      "loss: 0.523243  [ 2600/16250]\n",
      "loss: 0.539209  [ 2640/16250]\n",
      "loss: 0.500988  [ 2680/16250]\n",
      "loss: 0.517193  [ 2720/16250]\n",
      "loss: 0.538631  [ 2760/16250]\n",
      "loss: 0.509578  [ 2800/16250]\n",
      "loss: 0.538816  [ 2840/16250]\n",
      "loss: 0.528737  [ 2880/16250]\n",
      "loss: 0.512349  [ 2920/16250]\n",
      "loss: 0.537878  [ 2960/16250]\n",
      "loss: 0.517285  [ 3000/16250]\n",
      "loss: 0.526947  [ 3040/16250]\n",
      "loss: 0.528302  [ 3080/16250]\n",
      "loss: 0.566625  [ 3120/16250]\n",
      "loss: 0.530464  [ 3160/16250]\n",
      "loss: 0.515521  [ 3200/16250]\n",
      "loss: 0.531250  [ 3240/16250]\n",
      "loss: 0.520826  [ 3280/16250]\n",
      "loss: 0.554754  [ 3320/16250]\n",
      "loss: 0.556284  [ 3360/16250]\n",
      "loss: 0.529705  [ 3400/16250]\n",
      "loss: 0.517449  [ 3440/16250]\n",
      "loss: 0.507958  [ 3480/16250]\n",
      "loss: 0.549406  [ 3520/16250]\n",
      "loss: 0.510495  [ 3560/16250]\n",
      "loss: 0.560059  [ 3600/16250]\n",
      "loss: 0.514017  [ 3640/16250]\n",
      "loss: 0.513699  [ 3680/16250]\n",
      "loss: 0.539701  [ 3720/16250]\n",
      "loss: 0.520202  [ 3760/16250]\n",
      "loss: 0.517332  [ 3800/16250]\n",
      "loss: 0.517124  [ 3840/16250]\n",
      "loss: 0.533845  [ 3880/16250]\n",
      "loss: 0.523716  [ 3920/16250]\n",
      "loss: 0.517073  [ 3960/16250]\n",
      "loss: 0.521741  [ 4000/16250]\n",
      "loss: 0.518934  [ 4040/16250]\n",
      "loss: 0.523037  [ 4080/16250]\n",
      "loss: 0.507998  [ 4120/16250]\n",
      "loss: 0.516587  [ 4160/16250]\n",
      "loss: 0.533692  [ 4200/16250]\n",
      "loss: 0.507092  [ 4240/16250]\n",
      "loss: 0.541273  [ 4280/16250]\n",
      "loss: 0.518045  [ 4320/16250]\n",
      "loss: 0.528854  [ 4360/16250]\n",
      "loss: 0.509986  [ 4400/16250]\n",
      "loss: 0.504082  [ 4440/16250]\n",
      "loss: 0.534816  [ 4480/16250]\n",
      "loss: 0.533061  [ 4520/16250]\n",
      "loss: 0.502049  [ 4560/16250]\n",
      "loss: 0.541814  [ 4600/16250]\n",
      "loss: 0.522922  [ 4640/16250]\n",
      "loss: 0.556564  [ 4680/16250]\n",
      "loss: 0.521588  [ 4720/16250]\n",
      "loss: 0.506519  [ 4760/16250]\n",
      "loss: 0.515198  [ 4800/16250]\n",
      "loss: 0.552243  [ 4840/16250]\n",
      "loss: 0.511688  [ 4880/16250]\n",
      "loss: 0.535348  [ 4920/16250]\n",
      "loss: 0.509189  [ 4960/16250]\n",
      "loss: 0.534961  [ 5000/16250]\n",
      "loss: 0.528718  [ 5040/16250]\n",
      "loss: 0.518452  [ 5080/16250]\n",
      "loss: 0.516818  [ 5120/16250]\n",
      "loss: 0.518629  [ 5160/16250]\n",
      "loss: 0.511012  [ 5200/16250]\n",
      "loss: 0.511995  [ 5240/16250]\n",
      "loss: 0.546468  [ 5280/16250]\n",
      "loss: 0.517062  [ 5320/16250]\n",
      "loss: 0.517883  [ 5360/16250]\n",
      "loss: 0.530992  [ 5400/16250]\n",
      "loss: 0.537919  [ 5440/16250]\n",
      "loss: 0.508530  [ 5480/16250]\n",
      "loss: 0.536869  [ 5520/16250]\n",
      "loss: 0.518529  [ 5560/16250]\n",
      "loss: 0.509008  [ 5600/16250]\n",
      "loss: 0.502311  [ 5640/16250]\n",
      "loss: 0.521775  [ 5680/16250]\n",
      "loss: 0.520661  [ 5720/16250]\n",
      "loss: 0.513179  [ 5760/16250]\n",
      "loss: 0.528565  [ 5800/16250]\n",
      "loss: 0.536127  [ 5840/16250]\n",
      "loss: 0.519676  [ 5880/16250]\n",
      "loss: 0.505144  [ 5920/16250]\n",
      "loss: 0.533097  [ 5960/16250]\n",
      "loss: 0.534395  [ 6000/16250]\n",
      "loss: 0.509062  [ 6040/16250]\n",
      "loss: 0.536873  [ 6080/16250]\n",
      "loss: 0.515513  [ 6120/16250]\n",
      "loss: 0.539017  [ 6160/16250]\n",
      "loss: 0.525482  [ 6200/16250]\n",
      "loss: 0.531533  [ 6240/16250]\n",
      "loss: 0.512768  [ 6280/16250]\n",
      "loss: 0.554072  [ 6320/16250]\n",
      "loss: 0.514646  [ 6360/16250]\n",
      "loss: 0.524865  [ 6400/16250]\n",
      "loss: 0.518299  [ 6440/16250]\n",
      "loss: 0.534333  [ 6480/16250]\n",
      "loss: 0.516250  [ 6520/16250]\n",
      "loss: 0.536660  [ 6560/16250]\n",
      "loss: 0.538666  [ 6600/16250]\n",
      "loss: 0.540088  [ 6640/16250]\n",
      "loss: 0.507960  [ 6680/16250]\n",
      "loss: 0.509785  [ 6720/16250]\n",
      "loss: 0.513720  [ 6760/16250]\n",
      "loss: 0.511403  [ 6800/16250]\n",
      "loss: 0.550545  [ 6840/16250]\n",
      "loss: 0.525792  [ 6880/16250]\n",
      "loss: 0.534320  [ 6920/16250]\n",
      "loss: 0.525053  [ 6960/16250]\n",
      "loss: 0.518894  [ 7000/16250]\n",
      "loss: 0.532927  [ 7040/16250]\n",
      "loss: 0.514727  [ 7080/16250]\n",
      "loss: 0.520538  [ 7120/16250]\n",
      "loss: 0.517064  [ 7160/16250]\n",
      "loss: 0.522729  [ 7200/16250]\n",
      "loss: 0.526845  [ 7240/16250]\n",
      "loss: 0.530529  [ 7280/16250]\n",
      "loss: 0.538358  [ 7320/16250]\n",
      "loss: 0.508421  [ 7360/16250]\n",
      "loss: 0.523425  [ 7400/16250]\n",
      "loss: 0.540155  [ 7440/16250]\n",
      "loss: 0.487685  [ 7480/16250]\n",
      "loss: 0.515447  [ 7520/16250]\n",
      "loss: 0.523983  [ 7560/16250]\n",
      "loss: 0.533888  [ 7600/16250]\n",
      "loss: 0.524758  [ 7640/16250]\n",
      "loss: 0.519710  [ 7680/16250]\n",
      "loss: 0.518989  [ 7720/16250]\n",
      "loss: 0.516242  [ 7760/16250]\n",
      "loss: 0.536147  [ 7800/16250]\n",
      "loss: 0.507357  [ 7840/16250]\n",
      "loss: 0.531748  [ 7880/16250]\n",
      "loss: 0.515422  [ 7920/16250]\n",
      "loss: 0.540953  [ 7960/16250]\n",
      "loss: 0.527113  [ 8000/16250]\n",
      "loss: 0.521793  [ 8040/16250]\n",
      "loss: 0.525478  [ 8080/16250]\n",
      "loss: 0.523750  [ 8120/16250]\n",
      "loss: 0.504284  [ 8160/16250]\n",
      "loss: 0.541871  [ 8200/16250]\n",
      "loss: 0.511419  [ 8240/16250]\n",
      "loss: 0.510123  [ 8280/16250]\n",
      "loss: 0.511098  [ 8320/16250]\n",
      "loss: 0.530772  [ 8360/16250]\n",
      "loss: 0.517139  [ 8400/16250]\n",
      "loss: 0.527682  [ 8440/16250]\n",
      "loss: 0.517338  [ 8480/16250]\n",
      "loss: 0.506607  [ 8520/16250]\n",
      "loss: 0.514856  [ 8560/16250]\n",
      "loss: 0.512590  [ 8600/16250]\n",
      "loss: 0.508157  [ 8640/16250]\n",
      "loss: 0.505129  [ 8680/16250]\n",
      "loss: 0.530402  [ 8720/16250]\n",
      "loss: 0.523405  [ 8760/16250]\n",
      "loss: 0.525617  [ 8800/16250]\n",
      "loss: 0.519099  [ 8840/16250]\n",
      "loss: 0.535963  [ 8880/16250]\n",
      "loss: 0.532741  [ 8920/16250]\n",
      "loss: 0.513952  [ 8960/16250]\n",
      "loss: 0.522484  [ 9000/16250]\n",
      "loss: 0.556818  [ 9040/16250]\n",
      "loss: 0.564369  [ 9080/16250]\n",
      "loss: 0.524873  [ 9120/16250]\n",
      "loss: 0.527767  [ 9160/16250]\n",
      "loss: 0.520651  [ 9200/16250]\n",
      "loss: 0.523830  [ 9240/16250]\n",
      "loss: 0.505781  [ 9280/16250]\n",
      "loss: 0.513760  [ 9320/16250]\n",
      "loss: 0.509482  [ 9360/16250]\n",
      "loss: 0.512076  [ 9400/16250]\n",
      "loss: 0.513829  [ 9440/16250]\n",
      "loss: 0.488048  [ 9480/16250]\n",
      "loss: 0.525385  [ 9520/16250]\n",
      "loss: 0.508597  [ 9560/16250]\n",
      "loss: 0.511638  [ 9600/16250]\n",
      "loss: 0.517790  [ 9640/16250]\n",
      "loss: 0.531118  [ 9680/16250]\n",
      "loss: 0.552096  [ 9720/16250]\n",
      "loss: 0.520101  [ 9760/16250]\n",
      "loss: 0.541823  [ 9800/16250]\n",
      "loss: 0.548081  [ 9840/16250]\n",
      "loss: 0.559333  [ 9880/16250]\n",
      "loss: 0.533992  [ 9920/16250]\n",
      "loss: 0.553671  [ 9960/16250]\n",
      "loss: 0.546511  [10000/16250]\n",
      "loss: 0.537261  [10040/16250]\n",
      "loss: 0.524807  [10080/16250]\n",
      "loss: 0.520158  [10120/16250]\n",
      "loss: 0.534077  [10160/16250]\n",
      "loss: 0.537793  [10200/16250]\n",
      "loss: 0.514186  [10240/16250]\n",
      "loss: 0.506413  [10280/16250]\n",
      "loss: 0.528469  [10320/16250]\n",
      "loss: 0.513219  [10360/16250]\n",
      "loss: 0.532802  [10400/16250]\n",
      "loss: 0.539936  [10440/16250]\n",
      "loss: 0.534263  [10480/16250]\n",
      "loss: 0.500313  [10520/16250]\n",
      "loss: 0.516423  [10560/16250]\n",
      "loss: 0.512073  [10600/16250]\n",
      "loss: 0.513849  [10640/16250]\n",
      "loss: 0.508838  [10680/16250]\n",
      "loss: 0.514950  [10720/16250]\n",
      "loss: 0.526597  [10760/16250]\n",
      "loss: 0.509711  [10800/16250]\n",
      "loss: 0.534933  [10840/16250]\n",
      "loss: 0.533838  [10880/16250]\n",
      "loss: 0.520035  [10920/16250]\n",
      "loss: 0.515852  [10960/16250]\n",
      "loss: 0.511261  [11000/16250]\n",
      "loss: 0.527391  [11040/16250]\n",
      "loss: 0.519283  [11080/16250]\n",
      "loss: 0.526338  [11120/16250]\n",
      "loss: 0.498643  [11160/16250]\n",
      "loss: 0.519615  [11200/16250]\n",
      "loss: 0.551485  [11240/16250]\n",
      "loss: 0.515115  [11280/16250]\n",
      "loss: 0.510914  [11320/16250]\n",
      "loss: 0.528736  [11360/16250]\n",
      "loss: 0.548748  [11400/16250]\n",
      "loss: 0.528041  [11440/16250]\n",
      "loss: 0.517583  [11480/16250]\n",
      "loss: 0.507888  [11520/16250]\n",
      "loss: 0.536092  [11560/16250]\n",
      "loss: 0.520552  [11600/16250]\n",
      "loss: 0.528189  [11640/16250]\n",
      "loss: 0.508585  [11680/16250]\n",
      "loss: 0.507912  [11720/16250]\n",
      "loss: 0.531811  [11760/16250]\n",
      "loss: 0.535511  [11800/16250]\n",
      "loss: 0.538585  [11840/16250]\n",
      "loss: 0.507531  [11880/16250]\n",
      "loss: 0.517551  [11920/16250]\n",
      "loss: 0.517835  [11960/16250]\n",
      "loss: 0.543946  [12000/16250]\n",
      "loss: 0.510816  [12040/16250]\n",
      "loss: 0.528674  [12080/16250]\n",
      "loss: 0.509454  [12120/16250]\n",
      "loss: 0.490216  [12160/16250]\n",
      "loss: 0.514515  [12200/16250]\n",
      "loss: 0.546163  [12240/16250]\n",
      "loss: 0.539041  [12280/16250]\n",
      "loss: 0.541276  [12320/16250]\n",
      "loss: 0.508571  [12360/16250]\n",
      "loss: 0.538927  [12400/16250]\n",
      "loss: 0.519923  [12440/16250]\n",
      "loss: 0.511288  [12480/16250]\n",
      "loss: 0.514628  [12520/16250]\n",
      "loss: 0.505486  [12560/16250]\n",
      "loss: 0.519526  [12600/16250]\n",
      "loss: 0.517444  [12640/16250]\n",
      "loss: 0.539324  [12680/16250]\n",
      "loss: 0.521753  [12720/16250]\n",
      "loss: 0.502276  [12760/16250]\n",
      "loss: 0.530612  [12800/16250]\n",
      "loss: 0.504881  [12840/16250]\n",
      "loss: 0.539943  [12880/16250]\n",
      "loss: 0.532364  [12920/16250]\n",
      "loss: 0.523458  [12960/16250]\n",
      "loss: 0.511821  [13000/16250]\n",
      "loss: 0.543172  [13040/16250]\n",
      "loss: 0.542267  [13080/16250]\n",
      "loss: 0.524165  [13120/16250]\n",
      "loss: 0.509358  [13160/16250]\n",
      "loss: 0.544700  [13200/16250]\n",
      "loss: 0.538159  [13240/16250]\n",
      "loss: 0.518668  [13280/16250]\n",
      "loss: 0.517860  [13320/16250]\n",
      "loss: 0.520528  [13360/16250]\n",
      "loss: 0.521425  [13400/16250]\n",
      "loss: 0.507532  [13440/16250]\n",
      "loss: 0.517333  [13480/16250]\n",
      "loss: 0.491184  [13520/16250]\n",
      "loss: 0.521688  [13560/16250]\n",
      "loss: 0.532059  [13600/16250]\n",
      "loss: 0.514381  [13640/16250]\n",
      "loss: 0.537538  [13680/16250]\n",
      "loss: 0.518636  [13720/16250]\n",
      "loss: 0.542040  [13760/16250]\n",
      "loss: 0.542562  [13800/16250]\n",
      "loss: 0.512807  [13840/16250]\n",
      "loss: 0.548663  [13880/16250]\n",
      "loss: 0.531128  [13920/16250]\n",
      "loss: 0.516151  [13960/16250]\n",
      "loss: 0.540913  [14000/16250]\n",
      "loss: 0.519012  [14040/16250]\n",
      "loss: 0.525093  [14080/16250]\n",
      "loss: 0.520013  [14120/16250]\n",
      "loss: 0.531632  [14160/16250]\n",
      "loss: 0.538016  [14200/16250]\n",
      "loss: 0.503970  [14240/16250]\n",
      "loss: 0.517545  [14280/16250]\n",
      "loss: 0.513410  [14320/16250]\n",
      "loss: 0.543772  [14360/16250]\n",
      "loss: 0.566197  [14400/16250]\n",
      "loss: 0.529832  [14440/16250]\n",
      "loss: 0.512091  [14480/16250]\n",
      "loss: 0.535958  [14520/16250]\n",
      "loss: 0.494913  [14560/16250]\n",
      "loss: 0.512325  [14600/16250]\n",
      "loss: 0.521504  [14640/16250]\n",
      "loss: 0.498220  [14680/16250]\n",
      "loss: 0.507167  [14720/16250]\n",
      "loss: 0.545858  [14760/16250]\n",
      "loss: 0.534080  [14800/16250]\n",
      "loss: 0.497953  [14840/16250]\n",
      "loss: 0.520957  [14880/16250]\n",
      "loss: 0.510925  [14920/16250]\n",
      "loss: 0.514945  [14960/16250]\n",
      "loss: 0.529691  [15000/16250]\n",
      "loss: 0.526225  [15040/16250]\n",
      "loss: 0.522548  [15080/16250]\n",
      "loss: 0.538099  [15120/16250]\n",
      "loss: 0.535674  [15160/16250]\n",
      "loss: 0.532085  [15200/16250]\n",
      "loss: 0.516178  [15240/16250]\n",
      "loss: 0.504383  [15280/16250]\n",
      "loss: 0.524096  [15320/16250]\n",
      "loss: 0.504839  [15360/16250]\n",
      "loss: 0.516495  [15400/16250]\n",
      "loss: 0.552922  [15440/16250]\n",
      "loss: 0.535165  [15480/16250]\n",
      "loss: 0.501972  [15520/16250]\n",
      "loss: 0.516710  [15560/16250]\n",
      "loss: 0.526099  [15600/16250]\n",
      "loss: 0.530399  [15640/16250]\n",
      "loss: 0.513159  [15680/16250]\n",
      "loss: 0.530775  [15720/16250]\n",
      "loss: 0.521025  [15760/16250]\n",
      "loss: 0.537497  [15800/16250]\n",
      "loss: 0.532643  [15840/16250]\n",
      "loss: 0.511682  [15880/16250]\n",
      "loss: 0.537188  [15920/16250]\n",
      "loss: 0.533844  [15960/16250]\n",
      "loss: 0.521749  [16000/16250]\n",
      "loss: 0.523224  [16040/16250]\n",
      "loss: 0.495539  [16080/16250]\n",
      "loss: 0.530978  [16120/16250]\n",
      "loss: 0.516903  [16160/16250]\n",
      "loss: 0.531594  [16200/16250]\n",
      "loss: 0.529549  [ 8120/16250]\n",
      "Avg loss: 0.844077 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.497160  [    0/16250]\n",
      "loss: 0.495968  [   40/16250]\n",
      "loss: 0.492798  [   80/16250]\n",
      "loss: 0.489522  [  120/16250]\n",
      "loss: 0.523585  [  160/16250]\n",
      "loss: 0.525555  [  200/16250]\n",
      "loss: 0.535944  [  240/16250]\n",
      "loss: 0.479846  [  280/16250]\n",
      "loss: 0.506703  [  320/16250]\n",
      "loss: 0.512311  [  360/16250]\n",
      "loss: 0.495193  [  400/16250]\n",
      "loss: 0.519329  [  440/16250]\n",
      "loss: 0.516482  [  480/16250]\n",
      "loss: 0.541197  [  520/16250]\n",
      "loss: 0.515815  [  560/16250]\n",
      "loss: 0.521827  [  600/16250]\n",
      "loss: 0.486580  [  640/16250]\n",
      "loss: 0.537503  [  680/16250]\n",
      "loss: 0.520336  [  720/16250]\n",
      "loss: 0.498572  [  760/16250]\n",
      "loss: 0.514921  [  800/16250]\n",
      "loss: 0.527588  [  840/16250]\n",
      "loss: 0.510672  [  880/16250]\n",
      "loss: 0.494888  [  920/16250]\n",
      "loss: 0.497136  [  960/16250]\n",
      "loss: 0.530596  [ 1000/16250]\n",
      "loss: 0.518298  [ 1040/16250]\n",
      "loss: 0.480354  [ 1080/16250]\n",
      "loss: 0.516551  [ 1120/16250]\n",
      "loss: 0.506025  [ 1160/16250]\n",
      "loss: 0.509346  [ 1200/16250]\n",
      "loss: 0.502982  [ 1240/16250]\n",
      "loss: 0.505626  [ 1280/16250]\n",
      "loss: 0.523697  [ 1320/16250]\n",
      "loss: 0.516244  [ 1360/16250]\n",
      "loss: 0.502769  [ 1400/16250]\n",
      "loss: 0.494749  [ 1440/16250]\n",
      "loss: 0.520617  [ 1480/16250]\n",
      "loss: 0.522592  [ 1520/16250]\n",
      "loss: 0.515828  [ 1560/16250]\n",
      "loss: 0.510804  [ 1600/16250]\n",
      "loss: 0.509761  [ 1640/16250]\n",
      "loss: 0.511642  [ 1680/16250]\n",
      "loss: 0.556696  [ 1720/16250]\n",
      "loss: 0.517915  [ 1760/16250]\n",
      "loss: 0.519058  [ 1800/16250]\n",
      "loss: 0.517662  [ 1840/16250]\n",
      "loss: 0.511469  [ 1880/16250]\n",
      "loss: 0.509925  [ 1920/16250]\n",
      "loss: 0.473817  [ 1960/16250]\n",
      "loss: 0.522015  [ 2000/16250]\n",
      "loss: 0.497455  [ 2040/16250]\n",
      "loss: 0.519193  [ 2080/16250]\n",
      "loss: 0.500890  [ 2120/16250]\n",
      "loss: 0.498796  [ 2160/16250]\n",
      "loss: 0.535509  [ 2200/16250]\n",
      "loss: 0.517914  [ 2240/16250]\n",
      "loss: 0.520092  [ 2280/16250]\n",
      "loss: 0.475115  [ 2320/16250]\n",
      "loss: 0.499768  [ 2360/16250]\n",
      "loss: 0.496795  [ 2400/16250]\n",
      "loss: 0.499053  [ 2440/16250]\n",
      "loss: 0.507337  [ 2480/16250]\n",
      "loss: 0.511511  [ 2520/16250]\n",
      "loss: 0.511763  [ 2560/16250]\n",
      "loss: 0.508583  [ 2600/16250]\n",
      "loss: 0.525412  [ 2640/16250]\n",
      "loss: 0.511336  [ 2680/16250]\n",
      "loss: 0.506062  [ 2720/16250]\n",
      "loss: 0.493997  [ 2760/16250]\n",
      "loss: 0.507490  [ 2800/16250]\n",
      "loss: 0.515970  [ 2840/16250]\n",
      "loss: 0.520750  [ 2880/16250]\n",
      "loss: 0.519567  [ 2920/16250]\n",
      "loss: 0.508645  [ 2960/16250]\n",
      "loss: 0.507419  [ 3000/16250]\n",
      "loss: 0.513802  [ 3040/16250]\n",
      "loss: 0.516289  [ 3080/16250]\n",
      "loss: 0.505342  [ 3120/16250]\n",
      "loss: 0.529542  [ 3160/16250]\n",
      "loss: 0.513462  [ 3200/16250]\n",
      "loss: 0.514628  [ 3240/16250]\n",
      "loss: 0.519310  [ 3280/16250]\n",
      "loss: 0.499192  [ 3320/16250]\n",
      "loss: 0.486092  [ 3360/16250]\n",
      "loss: 0.501900  [ 3400/16250]\n",
      "loss: 0.488818  [ 3440/16250]\n",
      "loss: 0.514526  [ 3480/16250]\n",
      "loss: 0.520312  [ 3520/16250]\n",
      "loss: 0.507408  [ 3560/16250]\n",
      "loss: 0.531404  [ 3600/16250]\n",
      "loss: 0.531993  [ 3640/16250]\n",
      "loss: 0.514315  [ 3680/16250]\n",
      "loss: 0.504989  [ 3720/16250]\n",
      "loss: 0.507341  [ 3760/16250]\n",
      "loss: 0.513438  [ 3800/16250]\n",
      "loss: 0.516115  [ 3840/16250]\n",
      "loss: 0.526129  [ 3880/16250]\n",
      "loss: 0.501088  [ 3920/16250]\n",
      "loss: 0.518138  [ 3960/16250]\n",
      "loss: 0.514154  [ 4000/16250]\n",
      "loss: 0.510842  [ 4040/16250]\n",
      "loss: 0.515796  [ 4080/16250]\n",
      "loss: 0.510534  [ 4120/16250]\n",
      "loss: 0.526405  [ 4160/16250]\n",
      "loss: 0.541076  [ 4200/16250]\n",
      "loss: 0.517195  [ 4240/16250]\n",
      "loss: 0.502757  [ 4280/16250]\n",
      "loss: 0.493396  [ 4320/16250]\n",
      "loss: 0.543480  [ 4360/16250]\n",
      "loss: 0.492033  [ 4400/16250]\n",
      "loss: 0.500940  [ 4440/16250]\n",
      "loss: 0.507353  [ 4480/16250]\n",
      "loss: 0.506594  [ 4520/16250]\n",
      "loss: 0.547463  [ 4560/16250]\n",
      "loss: 0.536247  [ 4600/16250]\n",
      "loss: 0.522435  [ 4640/16250]\n",
      "loss: 0.492760  [ 4680/16250]\n",
      "loss: 0.486636  [ 4720/16250]\n",
      "loss: 0.503227  [ 4760/16250]\n",
      "loss: 0.513477  [ 4800/16250]\n",
      "loss: 0.504518  [ 4840/16250]\n",
      "loss: 0.532688  [ 4880/16250]\n",
      "loss: 0.518730  [ 4920/16250]\n",
      "loss: 0.517579  [ 4960/16250]\n",
      "loss: 0.523087  [ 5000/16250]\n",
      "loss: 0.487314  [ 5040/16250]\n",
      "loss: 0.519022  [ 5080/16250]\n",
      "loss: 0.492265  [ 5120/16250]\n",
      "loss: 0.493372  [ 5160/16250]\n",
      "loss: 0.526197  [ 5200/16250]\n",
      "loss: 0.516846  [ 5240/16250]\n",
      "loss: 0.545353  [ 5280/16250]\n",
      "loss: 0.504785  [ 5320/16250]\n",
      "loss: 0.504134  [ 5360/16250]\n",
      "loss: 0.503112  [ 5400/16250]\n",
      "loss: 0.495411  [ 5440/16250]\n",
      "loss: 0.501935  [ 5480/16250]\n",
      "loss: 0.507921  [ 5520/16250]\n",
      "loss: 0.515349  [ 5560/16250]\n",
      "loss: 0.508758  [ 5600/16250]\n",
      "loss: 0.505536  [ 5640/16250]\n",
      "loss: 0.512582  [ 5680/16250]\n",
      "loss: 0.537746  [ 5720/16250]\n",
      "loss: 0.504555  [ 5760/16250]\n",
      "loss: 0.510537  [ 5800/16250]\n",
      "loss: 0.506841  [ 5840/16250]\n",
      "loss: 0.504110  [ 5880/16250]\n",
      "loss: 0.509894  [ 5920/16250]\n",
      "loss: 0.508151  [ 5960/16250]\n",
      "loss: 0.514138  [ 6000/16250]\n",
      "loss: 0.526057  [ 6040/16250]\n",
      "loss: 0.507274  [ 6080/16250]\n",
      "loss: 0.509736  [ 6120/16250]\n",
      "loss: 0.503213  [ 6160/16250]\n",
      "loss: 0.505986  [ 6200/16250]\n",
      "loss: 0.503203  [ 6240/16250]\n",
      "loss: 0.538727  [ 6280/16250]\n",
      "loss: 0.570619  [ 6320/16250]\n",
      "loss: 0.517108  [ 6360/16250]\n",
      "loss: 0.504913  [ 6400/16250]\n",
      "loss: 0.527108  [ 6440/16250]\n",
      "loss: 0.503670  [ 6480/16250]\n",
      "loss: 0.506470  [ 6520/16250]\n",
      "loss: 0.496304  [ 6560/16250]\n",
      "loss: 0.502780  [ 6600/16250]\n",
      "loss: 0.514967  [ 6640/16250]\n",
      "loss: 0.494929  [ 6680/16250]\n",
      "loss: 0.505787  [ 6720/16250]\n",
      "loss: 0.485074  [ 6760/16250]\n",
      "loss: 0.494971  [ 6800/16250]\n",
      "loss: 0.514280  [ 6840/16250]\n",
      "loss: 0.520985  [ 6880/16250]\n",
      "loss: 0.485203  [ 6920/16250]\n",
      "loss: 0.486611  [ 6960/16250]\n",
      "loss: 0.535108  [ 7000/16250]\n",
      "loss: 0.526098  [ 7040/16250]\n",
      "loss: 0.518116  [ 7080/16250]\n",
      "loss: 0.519180  [ 7120/16250]\n",
      "loss: 0.500334  [ 7160/16250]\n",
      "loss: 0.499959  [ 7200/16250]\n",
      "loss: 0.513203  [ 7240/16250]\n",
      "loss: 0.519665  [ 7280/16250]\n",
      "loss: 0.523021  [ 7320/16250]\n",
      "loss: 0.518257  [ 7360/16250]\n",
      "loss: 0.502392  [ 7400/16250]\n",
      "loss: 0.519137  [ 7440/16250]\n",
      "loss: 0.530303  [ 7480/16250]\n",
      "loss: 0.493695  [ 7520/16250]\n",
      "loss: 0.499646  [ 7560/16250]\n",
      "loss: 0.515258  [ 7600/16250]\n",
      "loss: 0.528368  [ 7640/16250]\n",
      "loss: 0.485249  [ 7680/16250]\n",
      "loss: 0.549060  [ 7720/16250]\n",
      "loss: 0.523491  [ 7760/16250]\n",
      "loss: 0.505464  [ 7800/16250]\n",
      "loss: 0.509372  [ 7840/16250]\n",
      "loss: 0.521223  [ 7880/16250]\n",
      "loss: 0.509143  [ 7920/16250]\n",
      "loss: 0.516454  [ 7960/16250]\n",
      "loss: 0.518128  [ 8000/16250]\n",
      "loss: 0.492971  [ 8040/16250]\n",
      "loss: 0.515635  [ 8080/16250]\n",
      "loss: 0.522865  [ 8120/16250]\n",
      "loss: 0.510081  [ 8160/16250]\n",
      "loss: 0.509693  [ 8200/16250]\n",
      "loss: 0.516409  [ 8240/16250]\n",
      "loss: 0.513122  [ 8280/16250]\n",
      "loss: 0.502194  [ 8320/16250]\n",
      "loss: 0.535145  [ 8360/16250]\n",
      "loss: 0.515938  [ 8400/16250]\n",
      "loss: 0.491977  [ 8440/16250]\n",
      "loss: 0.533787  [ 8480/16250]\n",
      "loss: 0.497752  [ 8520/16250]\n",
      "loss: 0.506382  [ 8560/16250]\n",
      "loss: 0.497630  [ 8600/16250]\n",
      "loss: 0.509012  [ 8640/16250]\n",
      "loss: 0.510726  [ 8680/16250]\n",
      "loss: 0.496033  [ 8720/16250]\n",
      "loss: 0.507478  [ 8760/16250]\n",
      "loss: 0.543712  [ 8800/16250]\n",
      "loss: 0.502483  [ 8840/16250]\n",
      "loss: 0.528523  [ 8880/16250]\n",
      "loss: 0.513850  [ 8920/16250]\n",
      "loss: 0.522320  [ 8960/16250]\n",
      "loss: 0.504579  [ 9000/16250]\n",
      "loss: 0.497297  [ 9040/16250]\n",
      "loss: 0.521559  [ 9080/16250]\n",
      "loss: 0.506283  [ 9120/16250]\n",
      "loss: 0.492567  [ 9160/16250]\n",
      "loss: 0.500776  [ 9200/16250]\n",
      "loss: 0.503516  [ 9240/16250]\n",
      "loss: 0.535654  [ 9280/16250]\n",
      "loss: 0.514369  [ 9320/16250]\n",
      "loss: 0.517267  [ 9360/16250]\n",
      "loss: 0.521437  [ 9400/16250]\n",
      "loss: 0.513812  [ 9440/16250]\n",
      "loss: 0.492737  [ 9480/16250]\n",
      "loss: 0.517436  [ 9520/16250]\n",
      "loss: 0.518681  [ 9560/16250]\n",
      "loss: 0.506638  [ 9600/16250]\n",
      "loss: 0.510502  [ 9640/16250]\n",
      "loss: 0.518312  [ 9680/16250]\n",
      "loss: 0.494786  [ 9720/16250]\n",
      "loss: 0.496605  [ 9760/16250]\n",
      "loss: 0.504916  [ 9800/16250]\n",
      "loss: 0.508628  [ 9840/16250]\n",
      "loss: 0.497765  [ 9880/16250]\n",
      "loss: 0.499420  [ 9920/16250]\n",
      "loss: 0.550887  [ 9960/16250]\n",
      "loss: 0.511126  [10000/16250]\n",
      "loss: 0.510283  [10040/16250]\n",
      "loss: 0.500007  [10080/16250]\n",
      "loss: 0.483484  [10120/16250]\n",
      "loss: 0.540314  [10160/16250]\n",
      "loss: 0.506126  [10200/16250]\n",
      "loss: 0.502024  [10240/16250]\n",
      "loss: 0.488674  [10280/16250]\n",
      "loss: 0.506842  [10320/16250]\n",
      "loss: 0.536558  [10360/16250]\n",
      "loss: 0.496350  [10400/16250]\n",
      "loss: 0.533116  [10440/16250]\n",
      "loss: 0.515487  [10480/16250]\n",
      "loss: 0.533109  [10520/16250]\n",
      "loss: 0.510724  [10560/16250]\n",
      "loss: 0.509175  [10600/16250]\n",
      "loss: 0.513476  [10640/16250]\n",
      "loss: 0.551177  [10680/16250]\n",
      "loss: 0.540854  [10720/16250]\n",
      "loss: 0.490923  [10760/16250]\n",
      "loss: 0.526492  [10800/16250]\n",
      "loss: 0.518335  [10840/16250]\n",
      "loss: 0.507904  [10880/16250]\n",
      "loss: 0.498315  [10920/16250]\n",
      "loss: 0.488588  [10960/16250]\n",
      "loss: 0.510581  [11000/16250]\n",
      "loss: 0.506123  [11040/16250]\n",
      "loss: 0.486971  [11080/16250]\n",
      "loss: 0.501966  [11120/16250]\n",
      "loss: 0.505787  [11160/16250]\n",
      "loss: 0.533064  [11200/16250]\n",
      "loss: 0.493650  [11240/16250]\n",
      "loss: 0.507672  [11280/16250]\n",
      "loss: 0.541688  [11320/16250]\n",
      "loss: 0.509630  [11360/16250]\n",
      "loss: 0.504329  [11400/16250]\n",
      "loss: 0.529282  [11440/16250]\n",
      "loss: 0.510638  [11480/16250]\n",
      "loss: 0.529190  [11520/16250]\n",
      "loss: 0.514213  [11560/16250]\n",
      "loss: 0.534491  [11600/16250]\n",
      "loss: 0.512789  [11640/16250]\n",
      "loss: 0.537097  [11680/16250]\n",
      "loss: 0.522735  [11720/16250]\n",
      "loss: 0.511780  [11760/16250]\n",
      "loss: 0.545623  [11800/16250]\n",
      "loss: 0.528566  [11840/16250]\n",
      "loss: 0.511925  [11880/16250]\n",
      "loss: 0.523469  [11920/16250]\n",
      "loss: 0.508140  [11960/16250]\n",
      "loss: 0.505895  [12000/16250]\n",
      "loss: 0.534521  [12040/16250]\n",
      "loss: 0.525167  [12080/16250]\n",
      "loss: 0.504605  [12120/16250]\n",
      "loss: 0.518268  [12160/16250]\n",
      "loss: 0.530956  [12200/16250]\n",
      "loss: 0.508376  [12240/16250]\n",
      "loss: 0.497983  [12280/16250]\n",
      "loss: 0.495487  [12320/16250]\n",
      "loss: 0.498466  [12360/16250]\n",
      "loss: 0.520964  [12400/16250]\n",
      "loss: 0.524212  [12440/16250]\n",
      "loss: 0.522753  [12480/16250]\n",
      "loss: 0.506496  [12520/16250]\n",
      "loss: 0.508241  [12560/16250]\n",
      "loss: 0.536177  [12600/16250]\n",
      "loss: 0.497530  [12640/16250]\n",
      "loss: 0.496204  [12680/16250]\n",
      "loss: 0.513800  [12720/16250]\n",
      "loss: 0.553660  [12760/16250]\n",
      "loss: 0.490977  [12800/16250]\n",
      "loss: 0.500328  [12840/16250]\n",
      "loss: 0.507535  [12880/16250]\n",
      "loss: 0.536875  [12920/16250]\n",
      "loss: 0.508861  [12960/16250]\n",
      "loss: 0.495982  [13000/16250]\n",
      "loss: 0.491343  [13040/16250]\n",
      "loss: 0.515829  [13080/16250]\n",
      "loss: 0.513550  [13120/16250]\n",
      "loss: 0.491842  [13160/16250]\n",
      "loss: 0.496888  [13200/16250]\n",
      "loss: 0.517144  [13240/16250]\n",
      "loss: 0.497182  [13280/16250]\n",
      "loss: 0.511634  [13320/16250]\n",
      "loss: 0.526558  [13360/16250]\n",
      "loss: 0.495920  [13400/16250]\n",
      "loss: 0.501795  [13440/16250]\n",
      "loss: 0.522185  [13480/16250]\n",
      "loss: 0.505756  [13520/16250]\n",
      "loss: 0.516239  [13560/16250]\n",
      "loss: 0.513580  [13600/16250]\n",
      "loss: 0.502173  [13640/16250]\n",
      "loss: 0.521061  [13680/16250]\n",
      "loss: 0.516612  [13720/16250]\n",
      "loss: 0.515831  [13760/16250]\n",
      "loss: 0.521767  [13800/16250]\n",
      "loss: 0.505834  [13840/16250]\n",
      "loss: 0.491718  [13880/16250]\n",
      "loss: 0.483265  [13920/16250]\n",
      "loss: 0.522301  [13960/16250]\n",
      "loss: 0.535283  [14000/16250]\n",
      "loss: 0.488419  [14040/16250]\n",
      "loss: 0.500987  [14080/16250]\n",
      "loss: 0.509468  [14120/16250]\n",
      "loss: 0.516416  [14160/16250]\n",
      "loss: 0.493262  [14200/16250]\n",
      "loss: 0.493401  [14240/16250]\n",
      "loss: 0.523865  [14280/16250]\n",
      "loss: 0.523538  [14320/16250]\n",
      "loss: 0.489804  [14360/16250]\n",
      "loss: 0.510137  [14400/16250]\n",
      "loss: 0.501627  [14440/16250]\n",
      "loss: 0.491753  [14480/16250]\n",
      "loss: 0.508290  [14520/16250]\n",
      "loss: 0.538741  [14560/16250]\n",
      "loss: 0.515765  [14600/16250]\n",
      "loss: 0.497477  [14640/16250]\n",
      "loss: 0.495586  [14680/16250]\n",
      "loss: 0.533886  [14720/16250]\n",
      "loss: 0.519415  [14760/16250]\n",
      "loss: 0.501540  [14800/16250]\n",
      "loss: 0.470079  [14840/16250]\n",
      "loss: 0.512878  [14880/16250]\n",
      "loss: 0.489357  [14920/16250]\n",
      "loss: 0.522406  [14960/16250]\n",
      "loss: 0.514171  [15000/16250]\n",
      "loss: 0.501250  [15040/16250]\n",
      "loss: 0.500584  [15080/16250]\n",
      "loss: 0.506341  [15120/16250]\n",
      "loss: 0.497270  [15160/16250]\n",
      "loss: 0.519038  [15200/16250]\n",
      "loss: 0.540275  [15240/16250]\n",
      "loss: 0.530472  [15280/16250]\n",
      "loss: 0.520353  [15320/16250]\n",
      "loss: 0.505499  [15360/16250]\n",
      "loss: 0.510153  [15400/16250]\n",
      "loss: 0.492890  [15440/16250]\n",
      "loss: 0.509289  [15480/16250]\n",
      "loss: 0.486366  [15520/16250]\n",
      "loss: 0.500638  [15560/16250]\n",
      "loss: 0.514137  [15600/16250]\n",
      "loss: 0.525034  [15640/16250]\n",
      "loss: 0.518586  [15680/16250]\n",
      "loss: 0.505932  [15720/16250]\n",
      "loss: 0.497122  [15760/16250]\n",
      "loss: 0.506659  [15800/16250]\n",
      "loss: 0.516963  [15840/16250]\n",
      "loss: 0.516258  [15880/16250]\n",
      "loss: 0.502334  [15920/16250]\n",
      "loss: 0.532411  [15960/16250]\n",
      "loss: 0.508776  [16000/16250]\n",
      "loss: 0.533445  [16040/16250]\n",
      "loss: 0.507800  [16080/16250]\n",
      "loss: 0.508776  [16120/16250]\n",
      "loss: 0.519144  [16160/16250]\n",
      "loss: 0.525930  [16200/16250]\n",
      "loss: 0.482216  [ 8120/16250]\n",
      "Avg loss: 0.872587 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.520203  [    0/16250]\n",
      "loss: 0.483393  [   40/16250]\n",
      "loss: 0.484173  [   80/16250]\n",
      "loss: 0.485648  [  120/16250]\n",
      "loss: 0.502975  [  160/16250]\n",
      "loss: 0.511605  [  200/16250]\n",
      "loss: 0.494263  [  240/16250]\n",
      "loss: 0.489361  [  280/16250]\n",
      "loss: 0.492612  [  320/16250]\n",
      "loss: 0.496232  [  360/16250]\n",
      "loss: 0.514894  [  400/16250]\n",
      "loss: 0.496549  [  440/16250]\n",
      "loss: 0.491351  [  480/16250]\n",
      "loss: 0.499104  [  520/16250]\n",
      "loss: 0.470956  [  560/16250]\n",
      "loss: 0.495577  [  600/16250]\n",
      "loss: 0.496722  [  640/16250]\n",
      "loss: 0.500354  [  680/16250]\n",
      "loss: 0.491484  [  720/16250]\n",
      "loss: 0.503931  [  760/16250]\n",
      "loss: 0.503269  [  800/16250]\n",
      "loss: 0.495266  [  840/16250]\n",
      "loss: 0.500037  [  880/16250]\n",
      "loss: 0.490355  [  920/16250]\n",
      "loss: 0.504929  [  960/16250]\n",
      "loss: 0.487514  [ 1000/16250]\n",
      "loss: 0.495763  [ 1040/16250]\n",
      "loss: 0.506934  [ 1080/16250]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from torch import nn\n",
    "from UNet import U_Net\n",
    "from DataSource import train_dataloader,test_dataloader\n",
    "model = U_Net(1,2)\n",
    "model.load_state_dict(torch.load('model_weights_test_3.pth'))\n",
    "model.train()\n",
    "model = model.cuda()\n",
    "#仿照指导书设置超参数，不设置validation set\n",
    "learning_rate = 6\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "#功力还不太够，先按照pytorch tutorials的流程来仿照着写\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "#print(len(test_dataloader.dataset))\n",
    "for t in range(epochs):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    torch.save(model.state_dict(), 'model_weights_test_4.pth')\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
